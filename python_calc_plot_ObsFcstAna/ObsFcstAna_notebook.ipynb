{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from netCDF4 import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "from helper.read_GEOSldas import read_tilecoord, read_obs_param\n",
    "from helper.util import make_folder, array2grid\n",
    "from helper.plot import plotMap\n",
    "from helper.smapeasev2 import smapeasev2_ind2latlon\n",
    "from helper.compute_monthly_stats import compute_monthly_stats\n",
    "from helper.write_nc4 import write_sums_nc4\n",
    "\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "import sys \n",
    "import io\n",
    "\n",
    "sys.stdout = io.TextIOWrapper(open(sys.stdout.fileno(), 'wb', 0), write_through=True)\n",
    "sys.stderr = io.TextIOWrapper(open(sys.stderr.fileno(), 'wb', 0), write_through=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "expdir = '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/land_sweeper/'\n",
    "expid = 'LS_DAv8_M36'\n",
    "domain = 'SMAP_EASEv2_M36_GLOBAL'\n",
    "\n",
    "start_time = datetime(2020,1,1)\n",
    "end_time = datetime(2020,4,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a minimum threshold for the temporal data points to ensure statistical reliability\n",
    "# of the computed metrics. \n",
    "Nmin = 20\n",
    "\n",
    "# Base directory for storing monthly files\n",
    "# This can be the same as the experiment directory (expdir) or a different location\n",
    "out_path_mo = expdir+expid+'/output/'+domain+'/ana/ens_avg/'\n",
    "\n",
    "# Directory for diagnostic plots\n",
    "out_path = expdir+expid+'/output/'+domain+'/figures/'\n",
    "make_folder(out_path)\n",
    "\n",
    "# Variable list for computing sum and sum of squared\n",
    "var_list = ['obs_obs', 'obs_obsvar','obs_fcst','obs_fcstvar','obs_ana','obs_anavar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: \"''\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/amfox/Desktop/GEOSldas_diagnostics/python_calc_plot_ObsFcstAna/ObsFcstAna_notebook.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/amfox/Desktop/GEOSldas_diagnostics/python_calc_plot_ObsFcstAna/ObsFcstAna_notebook.ipynb#W3sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(fop):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/amfox/Desktop/GEOSldas_diagnostics/python_calc_plot_ObsFcstAna/ObsFcstAna_notebook.ipynb#W3sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFile not found: \u001b[39m\u001b[39m{\u001b[39;00mfop\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/amfox/Desktop/GEOSldas_diagnostics/python_calc_plot_ObsFcstAna/ObsFcstAna_notebook.ipynb#W3sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m obs_param \u001b[39m=\u001b[39m read_obs_param(fop)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/amfox/Desktop/GEOSldas_diagnostics/python_calc_plot_ObsFcstAna/ObsFcstAna_notebook.ipynb#W3sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m n_spec \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(obs_param)\n",
      "File \u001b[0;32m~/Desktop/GEOSldas_diagnostics/python_calc_plot_ObsFcstAna/helper/read_GEOSldas.py:47\u001b[0m, in \u001b[0;36mread_obs_param\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m     45\u001b[0m param[\u001b[39m'\u001b[39m\u001b[39mflistpath\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m fid\u001b[39m.\u001b[39mreadline()\u001b[39m.\u001b[39mstrip()\u001b[39m.\u001b[39mstrip(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     46\u001b[0m param[\u001b[39m'\u001b[39m\u001b[39mflistname\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m fid\u001b[39m.\u001b[39mreadline()\u001b[39m.\u001b[39mstrip()\u001b[39m.\u001b[39mstrip(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 47\u001b[0m param[\u001b[39m'\u001b[39m\u001b[39merrstd\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39;49m(fid\u001b[39m.\u001b[39;49mreadline()\u001b[39m.\u001b[39;49mstrip())\n\u001b[1;32m     48\u001b[0m param[\u001b[39m'\u001b[39m\u001b[39mstd_normal_max\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(fid\u001b[39m.\u001b[39mreadline()\u001b[39m.\u001b[39mstrip())\n\u001b[1;32m     49\u001b[0m param[\u001b[39m'\u001b[39m\u001b[39mzeromean\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m fid\u001b[39m.\u001b[39mreadline()\u001b[39m.\u001b[39mstrip()\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: \"''\""
     ]
    }
   ],
   "source": [
    "# Read tilecoord and obsparam for tile and obs species information\n",
    "ftc = expdir+expid+'/output/'+domain+'/rc_out/'+expid+'.ldas_tilecoord.bin'\n",
    "tc = read_tilecoord(ftc)\n",
    "n_tile = tc['N_tile']\n",
    "\n",
    "# fop = expdir+expid+'/output/'+domain+'/rc_out/Y2020/M01/'+expid+'.ldas_obsparam.20200101_0000z.txt'\n",
    "fop = expdir+expid+'/output/'+domain+'/rc_out/Y2020/M01/SPL4SM_Tv7031.ldas_obsparam.20250214_0000z.txt'\n",
    "if not os.path.exists(fop):\n",
    "    raise FileNotFoundError(f\"File not found: {fop}\")\n",
    "obs_param = read_obs_param(fop)\n",
    "n_spec = len(obs_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize statistical metrics \n",
    "data_sum = {}\n",
    "data2_sum = {}\n",
    "N_data = np.zeros((n_tile, n_spec))\n",
    "oxf_sum = np.zeros((n_tile, n_spec))\n",
    "oxa_sum = np.zeros((n_tile, n_spec))\n",
    "fxa_sum = np.zeros((n_tile, n_spec))\n",
    "\n",
    "for var in var_list:\n",
    "    data_sum[var] = np.zeros((n_tile, n_spec))\n",
    "    data2_sum[var] = np.zeros((n_tile, n_spec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time loop: processing data at monthly time step\n",
    "date_time = start_time\n",
    "while date_time < end_time:\n",
    "    # File to store monthly statistics    \n",
    "    fout_path = out_path_mo + '/Y'+ date_time.strftime('%Y') + '/M' + date_time.strftime('%m') + '/'\n",
    "    make_folder(fout_path)\n",
    "    \n",
    "    fout = fout_path + expid+'.ens_avg.ldas_ObsFcstAna.' + date_time.strftime('%Y%m') +'_stats.nc4'\n",
    "\n",
    "    # Read monthly data if file exists, otherwise compute monthly statistics first   \n",
    "    if os.path.isfile(fout):\n",
    "        print('read sums from  monthly file: '+fout)\n",
    "        mdata_sum = {}\n",
    "        mdata2_sum = {}\n",
    "        with Dataset(fout,'r') as nc:\n",
    "            mN_data = nc.variables['N_data'][:]\n",
    "            moxf_sum = nc.variables['obsxfcst_sum'][:]\n",
    "            moxa_sum = nc.variables['obsxana_sum'][:]\n",
    "            mfxa_sum = nc.variables['fcstxana_sum'][:]\n",
    "            for var in var_list:\n",
    "                mdata_sum[var] = nc.variables[var+'_sum'][:]\n",
    "                mdata2_sum[var] = nc.variables[var+'2_sum'][:]\n",
    "    else:\n",
    "        print('compute monthly sums for '+date_time.strftime('%Y%m'))\n",
    "        mN_data, mdata_sum, mdata2_sum, moxf_sum, moxa_sum, mfxa_sum = \\\n",
    "                 compute_monthly_stats(expdir,expid,domain,date_time,tc,obs_param,var_list)\n",
    "        print('save to monthly file: '+fout)\n",
    "        write_sums_nc4(fout, mN_data,mdata_sum, mdata2_sum, moxf_sum, moxa_sum, mfxa_sum, obs_param)\n",
    "\n",
    "    # Aggregate monthly data\n",
    "    N_data += mN_data\n",
    "    oxf_sum += moxf_sum\n",
    "    oxa_sum += moxa_sum\n",
    "    fxa_sum += mfxa_sum\n",
    "   \n",
    "    for var in var_list:\n",
    "        data_sum[var] += mdata_sum[var] \n",
    "        data2_sum[var] += mdata2_sum[var]  \n",
    "        \n",
    "    date_time =date_time + relativedelta(months=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the final statistics\n",
    "# This section calculate the final statistical metrics based on the accumulated data.\n",
    "data_mean ={}\n",
    "data2_mean = {}\n",
    "data_var = {}\n",
    "\n",
    "# First, compute the metrics of individual variables  \n",
    "for var in var_list:\n",
    "    data_sum[var][N_data == 0] = np.nan\n",
    "    data2_sum[var][N_data == 0] = np.nan\n",
    "    \n",
    "    data_mean[var]  = data_sum[var] / N_data\n",
    "    data2_mean[var] = data2_sum[var] /N_data\n",
    "    # var(x) = E[x2] - (E[x])^2\n",
    "    data_var[var] = data2_mean[var] - data_mean[var]**2\n",
    "    \n",
    "oxf_sum[N_data == 0] = np.nan\n",
    "oxa_sum[N_data == 0] = np.nan\n",
    "fxa_sum[N_data == 0] = np.nan\n",
    "# E[xy]\n",
    "oxf_mean = oxf_sum / N_data\n",
    "oxa_mean = oxa_sum / N_data\n",
    "fxa_mean = fxa_sum / N_data\n",
    "\n",
    "# Then computer metrics of O-F, O-A, etc. based on above computed \n",
    "# mean(x-y) = E[x] - E[y]   \n",
    "OmF_mean = data_mean['obs_obs'] - data_mean['obs_fcst']\n",
    "OmA_mean = data_mean['obs_obs'] - data_mean['obs_ana']\n",
    "# var(x-y) = var(x) + var(y) - 2cov(x,y)\n",
    "# cov(x,y) = E[xy] - E[x]E[y]\n",
    "OmF_stdv  = np.sqrt(data_var['obs_obs'] + data_var['obs_fcst'] - \\\n",
    "                       2 * (oxf_mean - data_mean['obs_obs']*data_mean['obs_fcst']))\n",
    "                    \n",
    "OmA_stdv  = np.sqrt(data_var['obs_obs'] + data_var['obs_ana'] - \\\n",
    "                       2 * (oxa_mean - data_mean['obs_obs']*data_mean['obs_ana']))\n",
    "\n",
    "OmF_norm_mean = OmF_mean / np.sqrt(data_mean['obs_obsvar'] + data_mean['obs_fcstvar']) \n",
    "OmF_norm_stdv = np.sqrt(OmF_stdv**2 / (data_mean['obs_obsvar'] + data_mean['obs_fcstvar']) )\n",
    "    \n",
    "# Mask out data points with insufficent observations using the Nmin threshold\n",
    "# Do NOT apply to N_data\n",
    "OmF_mean[N_data < Nmin] = np.nan\n",
    "OmF_stdv[N_data < Nmin] = np.nan\n",
    "OmF_norm_mean[N_data < Nmin] = np.nan\n",
    "OmF_norm_stdv[N_data < Nmin] = np.nan\n",
    "OmA_mean[N_data < Nmin] = np.nan\n",
    "OmA_stdv[N_data < Nmin] = np.nan\n",
    "\n",
    "# Combine metrics of individual species using weighted averaging\n",
    "OmF_mean = np.nansum(OmF_mean*N_data, axis=1)/np.nansum(N_data,axis=1)\n",
    "OmF_stdv = np.nansum(OmF_stdv*N_data,axis=1)/np.nansum(N_data,axis=1)\n",
    "OmF_norm_mean = np.nansum(OmF_norm_mean*N_data, axis=1)/np.nansum(N_data,axis=1)\n",
    "OmF_norm_stdv = np.nansum(OmF_norm_stdv*N_data,axis=1)/np.nansum(N_data,axis=1)\n",
    "OmA_mean = np.nansum(OmA_mean*N_data, axis=1)/np.nansum(N_data,axis=1)\n",
    "OmA_stdv = np.nansum(OmA_stdv*N_data,axis=1)/np.nansum(N_data,axis=1)\n",
    "Nobs_data = np.nansum(N_data, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "fig, axes = plt.subplots(2,2, figsize=(18,10))\n",
    "plt.rcParams.update({'font.size':14})\n",
    "\n",
    "for i in np.arange(2):\n",
    "    for j in np.arange(2):\n",
    "        units = '[k]'\n",
    "        if i == 0 and j == 0:\n",
    "            tile_data = Nobs_data\n",
    "            # crange is [cmin, cmax]\n",
    "            crange =[0, np.ceil((end_time-start_time).days/150)*300]\n",
    "            colormap = plt.get_cmap('jet',20)\n",
    "            title_txt = expid + ' Tb Nobs '+ start_time.strftime('%Y%m')+'_'+end_time.strftime('%Y%m')\n",
    "            units = '[-]'\n",
    "        if i == 0 and j ==1:\n",
    "            tile_data = OmF_mean\n",
    "            crange =[-3, 3]\n",
    "            colormap = plt.get_cmap('bwr', 15) \n",
    "            title_txt = expid + ' Tb O-F mean '+ start_time.strftime('%Y%m')+'_'+end_time.strftime('%Y%m')\n",
    "        if i == 1 and j == 0:\n",
    "            tile_data = OmF_stdv\n",
    "            crange =[0, 15]\n",
    "            colormap = plt.get_cmap ('jet',15)\n",
    "            title_txt = expid + ' Tb O-F stdv '+ start_time.strftime('%Y%m')+'_'+end_time.strftime('%Y%m')\n",
    "        if i == 1 and j == 1:\n",
    "            tile_data = OmF_norm_stdv\n",
    "            crange =[0, 15]\n",
    "            colormap = plt.get_cmap ('jet',15)\n",
    "            title_txt = expid + ' Tb normalized O-F stdv '+ start_time.strftime('%Y%m%d')+'_'+end_time.strftime('%Y%m%d')\n",
    "\n",
    "        colormap.set_bad(color='0.9') # light grey, 0-black, 1-white\n",
    "\n",
    "        # Regrid 1d tile_data to 2d grid_data for map plots\n",
    "        if '_M09_' in domain: # special case  \n",
    "            grid_data_M09 = np.zeros((1624, 3856)) + np.nan  \n",
    "            grid_data_M09[tc['j_indg'],tc['i_indg']] = tile_data\n",
    "            \n",
    "            # Reshape the data into 4x4 blocks\n",
    "            reshaped = grid_data_M09.reshape(1624//4, 4, 3856//4, 4)\n",
    "\n",
    "            # Combine each 4x4 M09 block into a M36 grid\n",
    "            if i==0 and j==0:\n",
    "                grid_data = np.sum(reshaped,axis=(1, 3)) \n",
    "            else:\n",
    "                grid_data = np.nanmean(reshaped,axis=(1, 3))\n",
    "                \n",
    "            lat_M36, lon_M36 = smapeasev2_ind2latlon(np.arange(406), np.arange(964),'M36')\n",
    "            lon_2d,lat_2d = np.meshgrid(lon_M36,lat_M36)\n",
    "        else:\n",
    "            grid_data, uy,ux = array2grid(tile_data, lat = tc['com_lat'], lon = tc['com_lon'])\n",
    "            lon_2d,lat_2d = np.meshgrid(ux, uy)\n",
    "            \n",
    "        if 'normalized' in title_txt:\n",
    "            title_txt = title_txt + '\\n' + \"avg=%.3f, avg(abs(nstdv-1))=%.3f\" % (np.nanmean(grid_data), np.nanmean(np.abs(grid_data-1.)))+' '+units\n",
    "        elif 'mean' in title_txt:\n",
    "            title_txt = title_txt + '\\n' + \"avg=%.3f, avg(abs)=%.3f\" % (np.nanmean(grid_data), np.nanmean(np.abs(grid_data)))+' '+units\n",
    "        else:\n",
    "            title_txt = title_txt + '\\n' + \"avg=%.2f\" % (np.nanmean(grid_data)) +' '+units                \n",
    "\n",
    "        if 'normalized' in title_txt:\n",
    "            grid_data = np.log10(grid_data)\n",
    "            crange = [-0.6, 0.45]\n",
    "            \n",
    "        mm, cs = plotMap(grid_data, ax =axes[i,j], lat=lat_2d, lon=lon_2d, cRange=crange, \\\n",
    "                    title=title_txt, cmap=colormap, bounding=[-60, 80, -180,180])            \n",
    "\n",
    "plt.tight_layout()\n",
    "# Save figure to file\n",
    "fig.savefig(out_path+'Map_OmF_'+expid+'_'+start_time.strftime('%Y%m')+'_'+\\\n",
    "                    end_time.strftime('%Y%m')+'.png')\n",
    "#plt.show()\n",
    "plt.close(fig)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
