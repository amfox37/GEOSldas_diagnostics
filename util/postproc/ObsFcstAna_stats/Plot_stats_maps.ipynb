{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Sample script for computing/plotting data assimilation (DA) diagnostics from \n",
    "pre-saved monthly sums.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import sys;       sys.path.append('../../shared/python/')\n",
    "import warnings;  warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "\n",
    "import numpy             as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime               import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from netCDF4                import Dataset, num2date\n",
    "# from mpl_toolkits.basemap   import Basemap\n",
    "\n",
    "from read_GEOSldas          import read_tilecoord, read_obs_param\n",
    "from tile2grid              import tile2grid\n",
    "#from plot                   import plotMap\n",
    "from EASEv2                 import EASEv2_ind2latlon\n",
    "\n",
    "from postproc_ObsFcstAna    import postproc_ObsFcstAna\n",
    "\n",
    "# Uncomment if to run the script in the background to see the standard output while running \n",
    "# import io\n",
    "#sys.stdout = io.TextIOWrapper(open(sys.stdout.fileno(), 'wb', 0), write_through=True)\n",
    "#sys.stderr = io.TextIOWrapper(open(sys.stderr.fileno(), 'wb', 0), write_through=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User provided time range for processing (Year, Month, Day)\n",
    "start_time = datetime(2002,10,1)\n",
    "end_time   = datetime(2006,10,1)\n",
    "\n",
    "# -------------------------------- Experiments Information -----------------------------------------\n",
    "# Supports single experiment or multiple experiments.\n",
    "# All experiments must have identical tilecoords and number/order of observation species.\n",
    "# If the default \"species\" number/order do not match, need to set the *optional*\n",
    "#   \"select_species\" key to get a match, i.e. same species sequences.\n",
    "# This capability is required to enable calculating OmF/OmA statistics for one experiment\n",
    "#   using observations from another experiment. See note below.\n",
    "\n",
    "# exp_main = { 'expdir' : '/discover/nobackup/projects/land_da/CYGNSS_Experiments/OLv8_M36_Aus/',\n",
    "#                     'expid' : 'OLv8_M36_Aus',\n",
    "#                     'exptag': 'OL', \n",
    "#                     'domain':  'SMAP_EASEv2_M36_GLOBAL',\n",
    "#                     'da_t0' : 3,       # first hour of the month \n",
    "#                     'da_dt' : 10800}   # ObsFcstAna file interval in seconds\n",
    "\n",
    "# exp_sup1 = { 'expdir' : '/discover/nobackup/projects/land_da/CYGNSS_Experiments/DAv8_M36_Aus_v3/',\n",
    "#                     'expid' : 'DAv8_M36_Aus',\n",
    "#                     'exptag': 'DA', \n",
    "#                     'domain':  'SMAP_EASEv2_M36_GLOBAL',\n",
    "#                     'da_t0' : 3,       # first hour of the month \n",
    "#                     'da_dt' : 10800}   # ObsFcstAna file interval in seconds\n",
    "\n",
    "exp_main = { 'expdir' : '/discover/nobackup/projects/land_da/snow_qc_expts/1e_LS_DAv8_M36_0/',\n",
    "                    'expid' : '1e_LS_OLv8_M36_0',\n",
    "                    'exptag': 'OL', \n",
    "                    'domain':  'SMAP_EASEv2_M36_GLOBAL',\n",
    "                    'da_t0' : 3,       # first hour of the month \n",
    "                    'da_dt' : 10800}   # ObsFcstAna file interval in second\n",
    "\n",
    "exp_sup1 = { 'expdir' : '/discover/nobackup/projects/land_da/snow_qc_expts/1e_LS_DAv8_M36_0/',\n",
    "                    'expid' : '1e_LS_DAv8_M36_0',\n",
    "                    'exptag': 'DA', \n",
    "                    'domain':  'SMAP_EASEv2_M36_GLOBAL',\n",
    "                    'da_t0' : 3,       # first hour of the month \n",
    "                    'da_dt' : 10800}   # ObsFcstAna file interval in seconds\n",
    "\n",
    "\n",
    "# Uses forecasts/analyses from first experiment in list.\n",
    "# Observations from experiment specified by 'obs_from' index.\n",
    "# The mostly likely use case for this is that _scaled_ observations from a DA experiment\n",
    "#   are used to compute OmF etc diagnostics for a corresponding open loop experiment.\n",
    "\n",
    "exp_list = [exp_main, exp_sup1]\n",
    "obs_from = 1                            # obs is from \"exp_sup1\" (0-based indexing)\n",
    "if obs_from >= len(exp_list):\n",
    "    raise ValueError('Invalid \"obs_from\" value')\n",
    "\n",
    "\n",
    "# User provided monthly sum files directory\n",
    "monthly_sums_path = exp_list[0]['expdir']+exp_list[0]['expid']+ \\\n",
    "              '/output/'+exp_list[0]['domain']+'/ana/ens_avg/'\n",
    "\n",
    "# User provided output directory \n",
    "out_path = exp_list[0]['expdir']+exp_list[0]['expid']+ \\\n",
    "              '/output/'+exp_list[0]['domain']+'/figures/'\n",
    "os.makedirs(out_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add tilecoord and obs_param information to each experiment\n",
    "for exp in exp_list:\n",
    "    expdir   = exp['expdir']\n",
    "    expid    = exp['expid']\n",
    "    domain   = exp['domain']\n",
    "    fop      = expdir+expid+'/output/'+domain+'/rc_out/Y'+start_time.strftime('%Y')+'/M'+start_time.strftime('%m')+'/'+expid+'.ldas_obsparam.'+start_time.strftime('%Y%m%d')+'_0000z.txt'\n",
    "    obsparam = read_obs_param(fop)\n",
    "\n",
    "    # get the species list and default to list of all species if doesn't exist \n",
    "    species_list = exp.get('species_list',[int(obsparam[i]['species']) for i in range(len(obsparam))])\n",
    "    \n",
    "    # reorder obsparam to match across experiments\n",
    "    obsparam_new = []\n",
    "    for i in range(len(obsparam)):\n",
    "        if int(obsparam[i]['species']) in species_list:\n",
    "               obsparam_new.append(obsparam[i])              \n",
    "    obsparam = obsparam_new\n",
    "    \n",
    "    ftc = expdir+expid+'/output/'+ domain+'/rc_out/'+ expid+'.ldas_tilecoord.bin'\n",
    "    tc = read_tilecoord(ftc)\n",
    "\n",
    "    exp.update({'tilecoord':tc,'obsparam':obsparam})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(exp_list) >1 :\n",
    "    stats_file  = out_path + 'tmp_stats_'+exp_list[0]['exptag']+'_obsfrom_'+ \\\n",
    "                  exp_list[obs_from]['exptag']+'_'+start_time.strftime('%Y%m%d')+'_'+ \\\n",
    "                  end_time.strftime('%Y%m%d')+'.nc4'\n",
    "else:\n",
    "    stats_file  = out_path + 'tmp_stats_'+exp_list[0]['exptag']+'_'+ start_time.strftime('%Y%m%d')+'_'+ \\\n",
    "                  end_time.strftime('%Y%m%d')+'.nc4'\n",
    "    \n",
    "print('stats_file:', stats_file)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Postprocess raw ObsFcstAna output data into monthly sums for simpler and faster postprocessing;\n",
    "#  computes mean, variance from monthly sums that can be used to compute DA diagnostics directly\n",
    "\n",
    "if not os.path.isfile(stats_file):\n",
    "    # Initialize the postprocessing object\n",
    "    postproc = postproc_ObsFcstAna(exp_list, start_time, end_time, obs_from=obs_from)\n",
    "    # Step 1: Compute and save monthly sums \n",
    "    postproc.save_monthly_sum(monthly_sums_path)\n",
    "    # Step 2: Compute statistics from monthly sums, option to save result to file\n",
    "    stats = postproc.calculate_stats_from_sums(mo_path=monthly_sums_path, write_to_nc=True, filename=stats_file)\n",
    "else:\n",
    "    print('reading stats nc4 file '+stats_file)\n",
    "    stats = {}\n",
    "    with Dataset(stats_file,'r') as nc:\n",
    "        for key, value in nc.variables.items():\n",
    "            stats[key] = value[:].filled(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample of final compuation of selected diagnostic metrics \n",
    " \n",
    "Nmin = 20\n",
    "\n",
    "# Then computer metrics of O-F, O-A, etc. based on above computed\n",
    "N_data = stats['N_data']\n",
    "O_mean = stats['obs_mean']\n",
    "# mean(x-y) = E[x] - E[y]   \n",
    "OmF_mean = stats['obs_mean'] - stats['fcst_mean']\n",
    "OmA_mean = stats['obs_mean'] - stats['ana_mean']\n",
    "# var(x-y) = var(x) + var(y) - 2cov(x,y)\n",
    "# cov(x,y) = E[xy] - E[x]E[y]\n",
    "OmF_stdv  = np.sqrt(stats['obs_variance'] + stats['fcst_variance'] - \\\n",
    "                    2 * (stats['oxf_mean'] - stats['obs_mean']*stats['fcst_mean']))\n",
    "                    \n",
    "OmA_stdv  = np.sqrt(stats['obs_variance'] + stats['ana_variance'] - \\\n",
    "                    2 * (stats['oxa_mean'] - stats['obs_mean']*stats['ana_mean']))\n",
    "\n",
    " # \"fcstvar\" is assumed constant here for convenience. Modify if necessary\n",
    "OmF_norm_mean = OmF_mean / np.sqrt(stats['obsvar_mean'] + stats['fcstvar_mean']) \n",
    "OmF_norm_stdv = np.sqrt(OmF_stdv**2 / (stats['obsvar_mean'] + stats['fcstvar_mean']) )\n",
    "  \n",
    "# Mask out data points with insufficent observations using the Nmin threshold\n",
    "# Do NOT apply to N_data\n",
    "OmF_mean[     N_data < Nmin] = np.nan\n",
    "OmF_stdv[     N_data < Nmin] = np.nan\n",
    "OmF_norm_mean[N_data < Nmin] = np.nan\n",
    "OmF_norm_stdv[N_data < Nmin] = np.nan\n",
    "OmA_mean[     N_data < Nmin] = np.nan\n",
    "OmA_stdv[     N_data < Nmin] = np.nan\n",
    "N_data[       N_data < Nmin] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_obsparam(obsparam):\n",
    "    # Create groups based on instrument types\n",
    "    groups = {\n",
    "        'SMOS': [],    # SMOS Tb observations\n",
    "        'SMAP': [],    # SMAP Tb observations  \n",
    "        'ASCAT': [],   # ASCAT soil moisture\n",
    "        'MODIS': []    # MODIS snow cover\n",
    "    }\n",
    "    \n",
    "    # Map each species to its group based on description\n",
    "    for param in obsparam:\n",
    "        if 'SMOS_fit_Tb' in param['descr']:\n",
    "            groups['SMOS'].append(int(param['species']))\n",
    "        elif 'SMAP_L1C_Tb' in param['descr']:\n",
    "            groups['SMAP'].append(int(param['species']))\n",
    "        elif 'ASCAT' in param['descr']:\n",
    "            groups['ASCAT'].append(int(param['species']))\n",
    "        elif 'MOD10C1' in param['descr'] or 'MYD10C1' in param['descr']:\n",
    "            groups['MODIS'].append(int(param['species']))\n",
    "    \n",
    "    # Remove empty groups\n",
    "    return {k:v for k,v in groups.items() if v}\n",
    "\n",
    "sensor_groups = process_obsparam(obsparam)\n",
    "print(\"Grouped species by sensor:\")\n",
    "for sensor, species_list in sensor_groups.items():\n",
    "    print(f\"{sensor}: Species {species_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"OmF_stdv.shape:\", OmF_stdv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-diag]",
   "language": "python",
   "name": "conda-env-.conda-diag-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
