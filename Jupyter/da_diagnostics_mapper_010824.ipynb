{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from my_functions import read_obsfcstana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of paths\n",
    "paths = ['/discover/nobackup/amfox/Experiments/DAv7_M36_ASCAT_type_2/DAv7_M36_ASCAT_type_2/output/SMAP_EASEv2_M36_GLOBAL/ana/ens_avg/Y2015/M04',\n",
    "         '/discover/nobackup/amfox/Experiments/DAv7_M36_ASCAT_type_2/DAv7_M36_ASCAT_type_2/output/SMAP_EASEv2_M36_GLOBAL/ana/ens_avg/Y2015/M05',\n",
    "         '/discover/nobackup/amfox/Experiments/DAv7_M36_ASCAT_type_2/DAv7_M36_ASCAT_type_2/output/SMAP_EASEv2_M36_GLOBAL/ana/ens_avg/Y2015/M06',\n",
    "         '/discover/nobackup/amfox/Experiments/DAv7_M36_ASCAT_type_2/DAv7_M36_ASCAT_type_2/output/SMAP_EASEv2_M36_GLOBAL/ana/ens_avg/Y2015/M07',\n",
    "         '/discover/nobackup/amfox/Experiments/DAv7_M36_ASCAT_type_2/DAv7_M36_ASCAT_type_2/output/SMAP_EASEv2_M36_GLOBAL/ana/ens_avg/Y2015/M08',\n",
    "         '/discover/nobackup/amfox/Experiments/DAv7_M36_ASCAT_type_2/DAv7_M36_ASCAT_type_2/output/SMAP_EASEv2_M36_GLOBAL/ana/ens_avg/Y2015/M09',\n",
    "         '/discover/nobackup/amfox/Experiments/DAv7_M36_ASCAT_type_2/DAv7_M36_ASCAT_type_2/output/SMAP_EASEv2_M36_GLOBAL/ana/ens_avg/Y2015/M10',\n",
    "         '/discover/nobackup/amfox/Experiments/DAv7_M36_ASCAT_type_2/DAv7_M36_ASCAT_type_2/output/SMAP_EASEv2_M36_GLOBAL/ana/ens_avg/Y2015/M11',\n",
    "         '/discover/nobackup/amfox/Experiments/DAv7_M36_ASCAT_type_2/DAv7_M36_ASCAT_type_2/output/SMAP_EASEv2_M36_GLOBAL/ana/ens_avg/Y2015/M12',\n",
    "         '/discover/nobackup/amfox/Experiments/DAv7_M36_ASCAT_type_2/DAv7_M36_ASCAT_type_2/output/SMAP_EASEv2_M36_GLOBAL/ana/ens_avg/Y2016/M01',\n",
    "         '/discover/nobackup/amfox/Experiments/DAv7_M36_ASCAT_type_2/DAv7_M36_ASCAT_type_2/output/SMAP_EASEv2_M36_GLOBAL/ana/ens_avg/Y2016/M02',\n",
    "         '/discover/nobackup/amfox/Experiments/DAv7_M36_ASCAT_type_2/DAv7_M36_ASCAT_type_2/output/SMAP_EASEv2_M36_GLOBAL/ana/ens_avg/Y2016/M03'\n",
    "        ]\n",
    "\n",
    "# Define the common file name start\n",
    "file_name_start = 'DAv7_M36_ASCAT_type_2.ens_avg.ldas_ObsFcstAna.20'\n",
    "\n",
    "# Define the print flag\n",
    "printflag = False\n",
    "\n",
    "# Initialize lists to store the returned values\n",
    "date_times = []\n",
    "obs_species_list = []\n",
    "obs_tilenum_list = []\n",
    "obs_lon_list = []\n",
    "obs_lat_list = []\n",
    "obs_obs_list = []\n",
    "obs_fcst_list = []\n",
    "obs_ana_list = []\n",
    "\n",
    "\n",
    "# Loop over the paths\n",
    "for path in paths:\n",
    "    # Call the read_obsfcstana function for the current path\n",
    "    date_time, obs_species, obs_tilenum, obs_lon, obs_lat, obs_obs, obs_obsvar, obs_fcst, obs_fcstvar, obs_ana, obs_anavar = read_obsfcstana(path, file_name_start, printflag)\n",
    "    \n",
    "    # Append the returned values to the lists\n",
    "    date_times.append(date_time)\n",
    "    obs_species_list.append(obs_species)\n",
    "    obs_tilenum_list.append(obs_tilenum)\n",
    "    obs_lon_list.append(obs_lon)\n",
    "    obs_lat_list.append(obs_lat)\n",
    "    obs_obs_list.append(obs_obs)\n",
    "    obs_fcst_list.append(obs_fcst)\n",
    "    obs_ana_list.append(obs_ana)\n",
    "\n",
    "# Combine the returned values from all paths\n",
    "date_time_out = np.concatenate(date_times)\n",
    "obs_species_out = np.concatenate(obs_species_list)\n",
    "obs_tilenum_out = np.concatenate(obs_tilenum_list)\n",
    "obs_lon_out = np.concatenate(obs_lon_list)\n",
    "obs_lat_out = np.concatenate(obs_lat_list)\n",
    "obs_obs_out = np.concatenate(obs_obs_list)\n",
    "obs_fcst_out = np.concatenate(obs_fcst_list)\n",
    "obs_ana_out = np.concatenate(obs_ana_list)\n",
    "\n",
    "# Save the returned values to a file including the first year in the paths\n",
    "np.savez('obsfcstana_2015_2016.npz', date_time=date_time_out, obs_species=obs_species_out, obs_tilenum=obs_tilenum_out, obs_lon=obs_lon_out, obs_lat=obs_lat_out, obs_obs=obs_obs_out, obs_fcst=obs_fcst_out, obs_ana=obs_ana_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of years\n",
    "years = ['2015', '2016', '2017', '2018', '2019', '2020', '2021']\n",
    "\n",
    "# Define the common file name start\n",
    "file_name_start = 'DAv7_M36_ASCAT_type_2.ens_avg.ldas_ObsFcstAna.20'\n",
    "\n",
    "# Define the print flag\n",
    "printflag = False\n",
    "\n",
    "# Loop over the years\n",
    "for i in range(len(years)-1):\n",
    "    # Define the current and next year\n",
    "    current_year = years[i]\n",
    "    next_year = years[i+1]\n",
    "    # Define the list of paths\n",
    "    paths = []\n",
    "    for month in range(4, 13):\n",
    "        path = f'/discover/nobackup/amfox/Experiments/DAv7_M36_ASCAT_type_2/DAv7_M36_ASCAT_type_2/output/SMAP_EASEv2_M36_GLOBAL/ana/ens_avg/Y{current_year}/M{month:02d}'\n",
    "        paths.append(path)\n",
    "\n",
    "    for month in range(1, 4):\n",
    "        path = f'/discover/nobackup/amfox/Experiments/DAv7_M36_ASCAT_type_2/DAv7_M36_ASCAT_type_2/output/SMAP_EASEv2_M36_GLOBAL/ana/ens_avg/Y{next_year}/M{month:02d}'\n",
    "        paths.append(path)\n",
    "    \n",
    "    # Initialize lists to store the returned values\n",
    "    date_times = []\n",
    "    obs_species_list = []\n",
    "    obs_tilenum_list = []\n",
    "    obs_lon_list = []\n",
    "    obs_lat_list = []\n",
    "    obs_obs_list = []\n",
    "    obs_fcst_list = []\n",
    "    obs_ana_list = []\n",
    "    \n",
    "    # Loop over the paths for the current year\n",
    "    for path in paths:\n",
    "        # Print the current path\n",
    "        print(\"Current path:\", path)\n",
    "\n",
    "        # Call the read_obsfcstana function for the current path\n",
    "        date_time, obs_species, obs_tilenum, obs_lon, obs_lat, obs_obs, obs_obsvar, obs_fcst, obs_fcstvar, obs_ana, obs_anavar = read_obsfcstana(current_path, file_name_start, printflag)\n",
    "        \n",
    "        # Append the returned values to the lists\n",
    "        date_times.append(date_time)\n",
    "        obs_species_list.append(obs_species)\n",
    "        obs_tilenum_list.append(obs_tilenum)\n",
    "        obs_lon_list.append(obs_lon)\n",
    "        obs_lat_list.append(obs_lat)\n",
    "        obs_obs_list.append(obs_obs)\n",
    "        obs_fcst_list.append(obs_fcst)\n",
    "        obs_ana_list.append(obs_ana)\n",
    "    \n",
    "    # Combine the returned values from all paths\n",
    "    date_time_out = np.concatenate(date_times)\n",
    "    obs_species_out = np.concatenate(obs_species_list)\n",
    "    obs_tilenum_out = np.concatenate(obs_tilenum_list)\n",
    "    obs_lon_out = np.concatenate(obs_lon_list)\n",
    "    obs_lat_out = np.concatenate(obs_lat_list)\n",
    "    obs_obs_out = np.concatenate(obs_obs_list)\n",
    "    obs_fcst_out = np.concatenate(obs_fcst_list)\n",
    "    obs_ana_out = np.concatenate(obs_ana_list)\n",
    "    \n",
    "    # Save the returned values to a file including the current year in the file name\n",
    "    np.savez(f'obsfcstana_{current_year}.npz', date_time=date_time_out, obs_species=obs_species_out, obs_tilenum=obs_tilenum_out, obs_lon=obs_lon_out, obs_lat=obs_lat_out, obs_obs=obs_obs_out, obs_fcst=obs_fcst_out, obs_ana=obs_ana_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "# Specify the path to the netCDF file\n",
    "file_path = '/discover/nobackup/amfox/Experiments/DAv7_M36_ASCAT_type_2/DAv7_M36_ASCAT_type_2/output/SMAP_EASEv2_M36_GLOBAL/cat/ens_avg/Y2015/M04/DAv7_M36_ASCAT_type_2.catch_progn_incr.20150402.nc4'\n",
    "\n",
    "# Open the netCDF file\n",
    "dataset = xr.open_dataset(file_path)\n",
    "\n",
    "# Extract the lon and lat variables\n",
    "lon = dataset['lon']\n",
    "lat = dataset['lat']\n",
    "\n",
    "# Print the dimensions of the variables\n",
    "print(f\"Dimensions of lon: {lon.shape}\")\n",
    "print(f\"Dimensions of lat: {lat.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open each of the saved files\n",
    "data_2015 = np.load('obsfcstana_2015.npz', allow_pickle=True)\n",
    "data_2016 = np.load('obsfcstana_2016.npz', allow_pickle=True)\n",
    "data_2017 = np.load('obsfcstana_2017.npz', allow_pickle=True)\n",
    "data_2018 = np.load('obsfcstana_2018.npz', allow_pickle=True)\n",
    "data_2019 = np.load('obsfcstana_2019.npz', allow_pickle=True)\n",
    "data_2020 = np.load('obsfcstana_2020.npz', allow_pickle=True)\n",
    "\n",
    "# Extract and combine the data from each of the files\n",
    "date_time = np.concatenate((data_2015['date_time'], data_2016['date_time'], data_2017['date_time'], data_2018['date_time'], data_2019['date_time'], data_2020['date_time']))\n",
    "obs_species = np.concatenate((data_2015['obs_species'], data_2016['obs_species'], data_2017['obs_species'], data_2018['obs_species'], data_2019['obs_species'], data_2020['obs_species']))\n",
    "obs_tilenum = np.concatenate((data_2015['obs_tilenum'], data_2016['obs_tilenum'], data_2017['obs_tilenum'], data_2018['obs_tilenum'], data_2019['obs_tilenum'], data_2020['obs_tilenum']))\n",
    "obs_lon = np.concatenate((data_2015['obs_lon'], data_2016['obs_lon'], data_2017['obs_lon'], data_2018['obs_lon'], data_2019['obs_lon'], data_2020['obs_lon']))\n",
    "obs_lat = np.concatenate((data_2015['obs_lat'], data_2016['obs_lat'], data_2017['obs_lat'], data_2018['obs_lat'], data_2019['obs_lat'], data_2020['obs_lat']))\n",
    "obs_obs = np.concatenate((data_2015['obs_obs'], data_2016['obs_obs'], data_2017['obs_obs'], data_2018['obs_obs'], data_2019['obs_obs'], data_2020['obs_obs']))\n",
    "obs_fcst = np.concatenate((data_2015['obs_fcst'], data_2016['obs_fcst'], data_2017['obs_fcst'], data_2018['obs_fcst'], data_2019['obs_fcst'], data_2020['obs_fcst']))\n",
    "obs_ana = np.concatenate((data_2015['obs_ana'], data_2016['obs_ana'], data_2017['obs_ana'], data_2018['obs_ana'], data_2019['obs_ana'], data_2020['obs_ana']))\n",
    "\n",
    "date_time = data_2015['date_time']\n",
    "obs_species = data_2015['obs_species']\n",
    "obs_tilenum = data_2015['obs_tilenum']\n",
    "obs_lon = data_2015['obs_lon']\n",
    "obs_lat = data_2015['obs_lat']\n",
    "obs_obs = data_2015['obs_obs']\n",
    "obs_fcst = data_2015['obs_fcst']\n",
    "obs_ana = data_2015['obs_ana']\n",
    "\n",
    "# Calculate obs minus fcst\n",
    "obs_minus_fcst = []\n",
    "for i in range(len(date_time)):\n",
    "    obs_minus_fcst_chunk = obs_obs[i] - obs_fcst[i]\n",
    "    obs_minus_fcst.append(obs_minus_fcst_chunk)\n",
    "\n",
    "# Calculate obs minus ana\n",
    "obs_minus_ana = []\n",
    "for i in range(len(date_time)):\n",
    "    obs_minus_ana_chunk = obs_obs[i] - obs_ana[i]\n",
    "    obs_minus_ana.append(obs_minus_ana_chunk)\n",
    "\n",
    "# Convert the lists to numpy arrays\n",
    "obs_minus_fcst = np.array(obs_minus_fcst)\n",
    "obs_minus_ana = np.array(obs_minus_ana)\n",
    "\n",
    "# Find unique tilenum values\n",
    "unique_tilenum = np.unique(obs_tilenum)\n",
    "\n",
    "# Find the number of unique tilenum values\n",
    "num_unique_tilenum = len(unique_tilenum)\n",
    "\n",
    "# Print the number of unique tilenum values\n",
    "print(f\"Number of unique tilenum values: {num_unique_tilenum}\")\n",
    "\n",
    "# Group the obs_obs values by tilenum\n",
    "obs_obs_grouped = []\n",
    "for i in range(num_unique_tilenum):\n",
    "    # Print the current tilenum every 100 tilenum values\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Current tilenum: {i}\")\n",
    "    obs_obs_grouped.append(obs_obs[obs_tilenum == unique_tilenum[i]])\n",
    "\n",
    "# Group the obs_fcst values by tilenum\n",
    "obs_fcst_grouped = []  \n",
    "for i in range(num_unique_tilenum):\n",
    "    obs_fcst_grouped.append(obs_fcst[obs_tilenum == unique_tilenum[i]])\n",
    "\n",
    "# Group the obs_ana values by tilenum\n",
    "obs_ana_grouped = []    \n",
    "for i in range(num_unique_tilenum):\n",
    "    obs_ana_grouped.append(obs_ana[obs_tilenum == unique_tilenum[i]])\n",
    "\n",
    "# Group the obs_minus_fcst values by tilenum\n",
    "obs_minus_fcst_grouped = []\n",
    "for i in range(num_unique_tilenum):\n",
    "    obs_minus_fcst_grouped.append(obs_minus_fcst[obs_tilenum == unique_tilenum[i]])\n",
    "\n",
    "# Group the obs_minus_ana values by tilenum\n",
    "obs_minus_ana_grouped = []\n",
    "for i in range(num_unique_tilenum):\n",
    "    obs_minus_ana_grouped.append(obs_minus_ana[obs_tilenum == unique_tilenum[i]])\n",
    "\n",
    "# Find the number of observations for each tilenum\n",
    "num_obs = []\n",
    "for i in range(num_unique_tilenum):\n",
    "    num_obs.append(len(obs_obs_grouped[i]))\n",
    "\n",
    "# Calculate the mean obs_obs for each tilenum\n",
    "mean_obs_obs = []\n",
    "for i in range(num_unique_tilenum):\n",
    "    mean_obs_obs.append(np.mean(obs_obs_grouped[i]))\n",
    "\n",
    "# Calculate the mean obs_fcst for each tilenum\n",
    "mean_obs_fcst = []\n",
    "for i in range(num_unique_tilenum):\n",
    "    mean_obs_fcst.append(np.mean(obs_fcst_grouped[i]))\n",
    "\n",
    "# Calculate the mean obs_ana for each tilenum\n",
    "mean_obs_ana = []\n",
    "for i in range(num_unique_tilenum):\n",
    "    mean_obs_ana.append(np.mean(obs_ana_grouped[i]))\n",
    "\n",
    "# Calculate the mean obs_minus_fcst for each tilenum\n",
    "mean_obs_minus_fcst = []\n",
    "for i in range(num_unique_tilenum):\n",
    "    mean_obs_minus_fcst.append(np.mean(obs_minus_fcst_grouped[i]))\n",
    "\n",
    "# Calculate the mean obs_minus_ana for each tilenum\n",
    "mean_obs_minus_ana = []\n",
    "for i in range(num_unique_tilenum):\n",
    "    mean_obs_minus_ana.append(np.mean(obs_minus_ana_grouped[i]))\n",
    "\n",
    "# Calculate the standard deviation of obs_minus_fcst for each tilenum\n",
    "std_obs_minus_fcst = []\n",
    "for i in range(num_unique_tilenum):\n",
    "    std_obs_minus_fcst.append(np.std(obs_minus_fcst_grouped[i]))\n",
    "\n",
    "# Calculate the standard deviation of obs_minus_ana for each tilenum\n",
    "std_obs_minus_ana = []\n",
    "for i in range(num_unique_tilenum):\n",
    "    std_obs_minus_ana.append(np.std(obs_minus_ana_grouped[i]))\n",
    "\n",
    "# Save all of the calculated values to a file\n",
    "np.savez('obsfcstana_stats.npz', unique_tilenum=unique_tilenum, num_obs=num_obs, mean_obs_obs=mean_obs_obs, mean_obs_fcst=mean_obs_fcst, mean_obs_ana=mean_obs_ana, mean_obs_minus_fcst=mean_obs_minus_fcst, mean_obs_minus_ana=mean_obs_minus_ana, std_obs_minus_fcst=std_obs_minus_fcst, std_obs_minus_ana=std_obs_minus_ana)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign lon and lat to each tilenum\n",
    "lon_tilenum = []\n",
    "lat_tilenum = []\n",
    "for i in range(num_unique_tilenum):\n",
    "    lon_tilenum.append(lon[unique_tilenum[i]])\n",
    "    lat_tilenum.append(lat[unique_tilenum[i]])\n",
    "\n",
    "# Convert the lists to numpy arrays\n",
    "lon_tilenum = np.array(lon_tilenum)\n",
    "lat_tilenum = np.array(lat_tilenum)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the arrays based on obs_tilenum\n",
    "sort_indices = np.argsort(obs_tilenum)\n",
    "sorted_obs_tilenum = obs_tilenum[sort_indices]\n",
    "sorted_obs_obs = obs_obs[sort_indices]\n",
    "sorted_obs_fcst = obs_fcst[sort_indices]\n",
    "sorted_obs_ana = obs_ana[sort_indices]\n",
    "sorted_obs_minus_fcst = obs_minus_fcst[sort_indices]\n",
    "sorted_obs_minus_ana = obs_minus_ana[sort_indices]\n",
    "\n",
    "# Find the unique tilenum values and their counts\n",
    "unique_tilenum, counts = np.unique(sorted_obs_tilenum, return_counts=True)\n",
    "\n",
    "# Calculate the indices where the groups should be split\n",
    "split_indices = np.cumsum(counts)[:-1]\n",
    "\n",
    "# Split the sorted arrays based on the split indices\n",
    "obs_obs_grouped = np.split(sorted_obs_obs, split_indices)\n",
    "obs_fcst_grouped = np.split(sorted_obs_fcst, split_indices)\n",
    "obs_ana_grouped = np.split(sorted_obs_ana, split_indices)\n",
    "obs_minus_fcst_grouped = np.split(sorted_obs_minus_fcst, split_indices)\n",
    "obs_minus_ana_grouped = np.split(sorted_obs_minus_ana, split_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the calculated values from the file\n",
    "data = np.load('DAv7_M36_obsfcstana_stats.npz', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "\n",
    "# Directory path to search for NetCDF files\n",
    "root_directory = '/discover/nobackup/amfox/Experiments/DAv7_M36_ASCAT_type_2/DAv7_M36_ASCAT_type_2/output/SMAP_EASEv2_M36_GLOBAL/cat/ens_avg'\n",
    "\n",
    "# Initialize an empty list to store the calculated sfmc_increment values\n",
    "sfmc_increment_list = []\n",
    "rzmc_increment_list = []\n",
    "\n",
    "# Recursively traverse the directory tree\n",
    "for root, dirs, files in os.walk(root_directory):\n",
    "    for filename in files:\n",
    "        if filename.endswith('.nc4') and filename.startswith('DAv7_M36_ASCAT_type_2.inst3_1d_lndfcstana_Nt'):\n",
    "            # Construct the full file path\n",
    "            file_path = os.path.join(root, filename)\n",
    "            \n",
    "            # Open the NetCDF file using xarray\n",
    "            ds = xr.open_dataset(file_path)\n",
    "            \n",
    "            # Extract the SFMC_ANA and SFMC_FCST variables\n",
    "            sfmc_ana = ds['SFMC_ANA']\n",
    "            sfmc_fcst = ds['SFMC_FCST']\n",
    "            rzmc_ana = ds['RZMC_ANA']\n",
    "            rzmc_fcst = ds['RZMC_FCST']\n",
    "            \n",
    "            # Calculate the sfmc_increment\n",
    "            sfmc_increment = sfmc_fcst - sfmc_ana\n",
    "            rzmc_increment = rzmc_fcst - rzmc_ana\n",
    "            \n",
    "            # Append the sfmc_increment values to the list\n",
    "            sfmc_increment_list.append(sfmc_increment)\n",
    "            rzmc_increment_list.append(rzmc_increment)\n",
    "            \n",
    "            # Close the NetCDF file\n",
    "            ds.close()\n",
    "\n",
    "# Concatenate the sfmc_increment values along the time dimension\n",
    "sfmc_increment_concat = xr.concat(sfmc_increment_list, dim='time')\n",
    "rzmc_increment_concat = xr.concat(rzmc_increment_list, dim='time')\n",
    "\n",
    "# Save the concatenated sfmc_increment values to a new NetCDF file\n",
    "sfmc_increment_concat.to_netcdf('DAv7_M36_ASCAT_type_2_sfmc_increments.nc')\n",
    "rzmc_increment_concat.to_netcdf('DAv7_M36_ASCAT_type_2_rzmc_increments.nc')\n",
    "\n",
    "# Save both the concatenated sfmc_increment and rzmc_increment values to a new npsavez file\n",
    "np.savez('DAv7_M36_ASCAT_type_2_increments.npz', sfmc_increment=sfmc_increment_concat, rzmc_increment=rzmc_increment_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean sfmc_increment for each tile along the time dimension\n",
    "mean_sfmc_increment = []\n",
    "std_sfmc_increment = []\n",
    "mean_rzmc_increment = []\n",
    "std_rzmc_increment = []\n",
    "\n",
    "for i in range(len(sfmc_increment_concat['tile'])):\n",
    "    mean_sfmc_increment.append(np.mean(sfmc_increment_concat[:, i]))\n",
    "    std_sfmc_increment.append(np.std(sfmc_increment_concat[:, i]))\n",
    "    mean_rzmc_increment.append(np.mean(rzmc_increment_concat[:, i]))\n",
    "    std_rzmc_increment.append(np.std(rzmc_increment_concat[:, i]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(file_path)\n",
    "\n",
    "lon = ds['lon']\n",
    "lat = ds['lat']\n",
    "\n",
    "n_tile = len(lat)\n",
    "\n",
    "obarray = np.empty([n_tile, 3])\n",
    "obarray[:, 1] = lon\n",
    "obarray[:, 2] = lat\n",
    "obarray[:, 0] = std_sfmc_increment\n",
    "    \n",
    "plot_global(obarray,False,'ASCAT std_sfmc_increment','(m3 m-3)')\n",
    "\n",
    "obarray[:, 0] = std_rzmc_increment\n",
    "    \n",
    "plot_global(obarray,False,'ASCAT std_rzmc_increment','(m3 m-3)')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
