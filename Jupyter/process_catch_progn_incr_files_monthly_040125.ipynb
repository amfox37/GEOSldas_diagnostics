{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "expt_name = 'LS_DAv8_M36'\n",
    "\n",
    "start_date = datetime(2020, 1, 1)\n",
    "end_date = datetime(2020, 1, 6)\n",
    "\n",
    "start_date_str = start_date.strftime('%Y%m%d')\n",
    "end_date_str = end_date.strftime('%Y%m%d')\n",
    "\n",
    "# Define the path directory\n",
    "root_directory = f'/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/land_sweeper/{expt_name}/output/SMAP_EASEv2_M36_GLOBAL/cat/ens_avg'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('time', 'tile')\n",
      "Coordinates:\n",
      "    *empty*\n",
      "{}\n",
      "('time', 'tile')\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 8B 2020-01-01\n",
      "{}\n",
      "Max snow_incr_count: 6, Min snow_incr_count: 0\n",
      "Max snow_incr_mean: nan, Min snow_incr_mean: nan\n"
     ]
    }
   ],
   "source": [
    "current_date = start_date\n",
    "while current_date <= end_date:\n",
    "    year_month_directory = os.path.join(root_directory, \n",
    "                                        f\"Y{current_date.year}\", \n",
    "                                        f\"M{current_date.month:02d}\")\n",
    "\n",
    "    # Find the files\n",
    "    files = glob.glob(f\"{year_month_directory}/*catch_progn_incr*.nc4\")\n",
    "\n",
    "    # Load the data\n",
    "    data = xr.open_mfdataset(files, combine='nested', concat_dim=\"time\")\n",
    "\n",
    "    wesnn1_incr = data['WESNN1_INCR']\n",
    "    wesnn2_incr = data['WESNN2_INCR']\n",
    "    wesnn3_incr = data['WESNN3_INCR']\n",
    "\n",
    "    snow_incr = wesnn1_incr + wesnn2_incr + wesnn3_incr\n",
    "    # Ensure snow_incr is properly defined\n",
    "    if not isinstance(snow_incr, xr.DataArray):\n",
    "        raise ValueError(\"snow_incr is not a valid xarray.DataArray\")\n",
    "\n",
    "    # Find snow increments that are larger than abs(0.001)\n",
    "    snow_incr = snow_incr.where(np.abs(snow_incr) > 0.001)\n",
    "\n",
    "    if not isinstance(snow_incr, xr.DataArray):\n",
    "        raise ValueError(\"snow_incr is not a valid xarray.DataArray\")\n",
    "    print(snow_incr.dims)  # Check dimensions\n",
    "    print(snow_incr.coords)  # Check coordinates\n",
    "    print(snow_incr.attrs)  # Check attributes\n",
    "\n",
    "    # Count and find the mean of the snow increments, ignoring NaNs\n",
    "    snow_incr_count = snow_incr.count(dim='time')\n",
    "    snow_incr_mean = snow_incr.mean(dim='time', skipna=True)  \n",
    "\n",
    "    # .expand_dims(time=[current_date])\n",
    "    snow_incr_count = snow_incr_count.expand_dims(time=[current_date])\n",
    "    snow_incr_mean = snow_incr_mean.expand_dims(time=[current_date])\n",
    "\n",
    "    if not isinstance(snow_incr_count, xr.DataArray):\n",
    "        raise ValueError(\"snow_incr is not a valid xarray.DataArray\")\n",
    "    print(snow_incr_count.dims)  # Check dimensions\n",
    "    print(snow_incr_count.coords)  # Check coordinates\n",
    "    print(snow_incr_count.attrs)  # Check attributes  \n",
    "\n",
    "    # Print the max and min values for incr_count and incr_mean\n",
    "    print(f\"Max snow_incr_count: {snow_incr_count.values.max()}, Min snow_incr_count: {snow_incr_count.values.min()}\")\n",
    "    print(f\"Max snow_incr_mean: {snow_incr_mean.values.max()}, Min snow_incr_mean: {snow_incr_mean.values.min()}\")\n",
    "\n",
    "  # Combine variables into a single dataset\n",
    "    output_data = xr.Dataset({\n",
    "        'snow_incr_count': snow_incr_count,\n",
    "        'snow_incr_mean': snow_incr_mean\n",
    "    })\n",
    "\n",
    "    # Save the data to a single file\n",
    "    output_filename = f\"{root_directory}/snow_incrs_{current_date.strftime('%Y%m')}.nc4\"\n",
    "    output_data.to_netcdf(output_filename)\n",
    "\n",
    "    # Increment the date\n",
    "    current_date += relativedelta(months=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # Define the variables to be extracted\n",
    "    variables = {\n",
    "    'sm_surface': 'SFMC',\n",
    "    'sm_rootzone': 'RZMC',\n",
    "    'sm_profile': 'PRMC',\n",
    "    'precipitation_total_surface_flux': 'PRECTOTCORRLAND',\n",
    "    'vegetation_greenness_fraction': 'GRN',\n",
    "    'leaf_area_index': 'LAI',\n",
    "    'snow_mass': 'SNOMASLAND',\n",
    "    'surface_temperature_of_land_incl_snow': 'TSURFLAND',\n",
    "    'soil_temperature_layer_1': 'TSOIL1',\n",
    "    'snowfall_land': 'PRECSNOCORRLAND',\n",
    "    'snow_depth_within_snow_covered_area_fraction_on_land': 'SNODPLAND',\n",
    "    'snowpack_evaporation_latent_heat_flux_on_land': 'LHLANDSBLN',\n",
    "    'overland_runoff_including_throughflow': 'RUNSURFLAND',\n",
    "    'baseflow_flux_land': 'BASEFLOWLAND',\n",
    "    'snowmelt_flux_land': 'SMLAND',\n",
    "    'total_evaporation_land': 'EVLAND',\n",
    "    'net_shortwave_flux_land': 'SWLAND',\n",
    "    'total_water_storage_land': 'TWLAND',\n",
    "    'fractional_area_of_snow_on_land': 'FRLANDSNO'  # New variable added\n",
    "    }\n",
    "\n",
    "    # Extract the variables and calculate the mean along the time dimension\n",
    "    data_extracted = data[list(variables.values())].mean(dim='time')\n",
    "\n",
    "    # Add a time dimension to the extracted data\n",
    "    data_extracted = data_extracted.expand_dims(time=[current_date])\n",
    "\n",
    "    # Save the data\n",
    "    output_directory = f'/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/land_sweeper/{expt_name}/output/SMAP_EASEv2_M36_GLOBAL/cat/ens_avg'\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    output_filename = os.path.join(output_directory, f\"{expt_name}.tavg24_1d_lnd_Nt.{current_date.strftime('%Y%m')}.nc\")\n",
    "    data_extracted.to_netcdf(output_filename)\n",
    "\n",
    "    # Increment the date\n",
    "    current_date += relativedelta(months=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
