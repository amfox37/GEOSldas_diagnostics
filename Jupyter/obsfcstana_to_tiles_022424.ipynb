{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e54fe27b-0c64-45d8-aa97-ab32db88b10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from mapper_functions import plot_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "524cb137-aae7-4e21-9ff2-0d28f5c30fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expt_name = 'DAv7_M36_ASCAT_type_13_no_catdef_fp', 'DAv7_M36_ASCAT_type_2_fp_precip'\n",
    "expt_name = 'DAv7_M36_ASCAT_type_2_fp_precip'\n",
    "\n",
    "start_date = datetime(2015, 4, 1)\n",
    "end_date = datetime(2015, 4, 20)\n",
    "\n",
    "start_date_str = start_date.strftime('%Y%m%d')\n",
    "end_date_str = end_date.strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1adbc728-ae57-401d-9794-4538488447c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of lon: (112573,)\n",
      "Dimensions of lat: (112573,)\n"
     ]
    }
   ],
   "source": [
    "# Specify the path to the netCDF file\n",
    "file_path = f'/discover/nobackup/amfox/Experiments/{expt_name}/{expt_name}/output/SMAP_EASEv2_M36_GLOBAL/cat/ens_avg/Y2015/M04/{expt_name}.catch_progn_incr.20150402.nc4'\n",
    "\n",
    "# Open the netCDF file\n",
    "dataset = xr.open_dataset(file_path)\n",
    "\n",
    "# Extract the lon and lat variables\n",
    "lon = dataset['lon']\n",
    "lat = dataset['lat']\n",
    "\n",
    "# Print the dimensions of the variables\n",
    "print(f\"Dimensions of lon: {lon.shape}\")\n",
    "print(f\"Dimensions of lat: {lat.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "680db75e-db14-461f-aa6c-2129437d8d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "years =  ['2015']\n",
      "Current year =  2015\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'DAv7_M36_ASCAT_type_13_test_catdef_20150401_20150420_obsfcstana_extend_datetime_2015.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m current_year \u001b[38;5;241m=\u001b[39m years[i]\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCurrent year = \u001b[39m\u001b[38;5;124m'\u001b[39m, current_year)\n\u001b[0;32m---> 16\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mexpt_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mstart_date_str\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mend_date_str\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_obsfcstana_extend_datetime_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcurrent_year\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.npz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m date_time\u001b[38;5;241m.\u001b[39mextend(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate_time\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     18\u001b[0m obs_species\u001b[38;5;241m.\u001b[39mextend(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobs_species\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/.conda/envs/diag/lib/python3.10/site-packages/numpy/lib/npyio.py:405\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    403\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 405\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    406\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'DAv7_M36_ASCAT_type_13_test_catdef_20150401_20150420_obsfcstana_extend_datetime_2015.npz'"
     ]
    }
   ],
   "source": [
    "date_time = []\n",
    "obs_species = []\n",
    "obs_tilenum = []\n",
    "obs_lon = []\n",
    "obs_lat = []\n",
    "obs_obs = []\n",
    "obs_fcst = []\n",
    "obs_ana = []\n",
    "\n",
    "years = [str(year) for year in range(start_date.year, end_date.year + 1)]\n",
    "print('years = ', years)\n",
    "for i in range(len(years)-1):\n",
    "    # Define the current and next year\n",
    "    current_year = years[i]\n",
    "    print('Current year = ', current_year)\n",
    "    data = np.load(f'{expt_name}_{start_date_str}_{end_date_str}_obsfcstana_extend_datetime_{current_year}.npz', allow_pickle=True)\n",
    "    date_time.extend(data['date_time'])\n",
    "    obs_species.extend(data['obs_species'])\n",
    "    obs_tilenum.extend(data['obs_tilenum'])\n",
    "    obs_lon.extend(data['obs_lon'])\n",
    "    obs_lat.extend(data['obs_lat'])\n",
    "    obs_obs.extend(data['obs_obs'])\n",
    "    obs_fcst.extend(data['obs_fcst'])\n",
    "    obs_ana.extend(data['obs_ana'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7636f685-9f10-4d90-9085-dc81d4e06db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to np arrays\n",
    "obs_species = np.array(obs_species)\n",
    "obs_tilenum = np.array(obs_tilenum)\n",
    "obs_lon = np.array(obs_lon)\n",
    "obs_lat = np.array(obs_lat)\n",
    "obs_obs = np.array(obs_obs)\n",
    "obs_fcst = np.array(obs_fcst)\n",
    "obs_ana = np.array(obs_ana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcbaf13-abe8-4c22-9371-1f4ece9d1860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate obs minus fcst\n",
    "obs_minus_fcst = []\n",
    "obs_minus_ana = []\n",
    "\n",
    "print('Number of obs = ', len(obs_obs))\n",
    "\n",
    "for i in range(len(obs_obs)):\n",
    "    obs_minus_fcst_chunk = obs_obs[i] - obs_fcst[i]\n",
    "    obs_minus_fcst.append(obs_minus_fcst_chunk)\n",
    "    obs_minus_ana_chunk = obs_obs[i] - obs_ana[i]\n",
    "    obs_minus_ana.append(obs_minus_ana_chunk)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973b55d0-ec23-4a42-9661-ea49dc2739d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the lists to numpy arrays\n",
    "obs_minus_fcst = np.array(obs_minus_fcst)\n",
    "obs_minus_ana = np.array(obs_minus_ana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c08734-e507-4a4c-a815-4bc811886d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find unique tilenum values\n",
    "unique_tilenum = np.unique(obs_tilenum)\n",
    "\n",
    "# Find the number of unique tilenum values\n",
    "num_unique_tilenum = len(unique_tilenum)\n",
    "\n",
    "# Print the number of unique tilenum values\n",
    "print(f\"Number of unique tilenum values: {num_unique_tilenum}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074bab8c-7585-4ee8-a365-8061c2959e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the arrays based on obs_tilenum\n",
    "sort_indices = np.argsort(obs_tilenum)\n",
    "sorted_obs_tilenum = obs_tilenum[sort_indices]\n",
    "sorted_obs_species = obs_species[sort_indices]\n",
    "sorted_obs_obs = obs_obs[sort_indices]\n",
    "sorted_obs_fcst = obs_fcst[sort_indices]\n",
    "sorted_obs_ana = obs_ana[sort_indices]\n",
    "sorted_obs_minus_fcst = obs_minus_fcst[sort_indices]\n",
    "sorted_obs_minus_ana = obs_minus_ana[sort_indices]\n",
    "\n",
    "# Find the unique tilenum values and their counts\n",
    "unique_tilenum, counts = np.unique(sorted_obs_tilenum, return_counts=True)\n",
    "\n",
    "# Calculate the indices where the groups should be split\n",
    "split_indices = np.cumsum(counts)[:-1]\n",
    "\n",
    "# Split the sorted arrays based on the split indices\n",
    "obs_species_grouped = np.split(sorted_obs_species, split_indices)\n",
    "obs_obs_grouped = np.split(sorted_obs_obs, split_indices)\n",
    "obs_fcst_grouped = np.split(sorted_obs_fcst, split_indices)\n",
    "obs_ana_grouped = np.split(sorted_obs_ana, split_indices)\n",
    "obs_minus_fcst_grouped = np.split(sorted_obs_minus_fcst, split_indices)\n",
    "obs_minus_ana_grouped = np.split(sorted_obs_minus_ana, split_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a082d1ef-770b-46fe-bb62-997bb9fcd11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the length of obs_obs_grouped\n",
    "print(f\"Length of obs_obs_grouped: {len(obs_obs_grouped)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295be33f-bd1a-486d-881c-e56f4851f4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign lon and lat to each tilenum\n",
    "lon_tilenum = []\n",
    "lat_tilenum = []\n",
    "for i in range(num_unique_tilenum):\n",
    "    lon_tilenum.append(lon[int(unique_tilenum[i])])\n",
    "    lat_tilenum.append(lat[int(unique_tilenum[i])])\n",
    "\n",
    "# Convert the lists to numpy arrays\n",
    "lon_tilenum = np.array(lon_tilenum)\n",
    "lat_tilenum = np.array(lat_tilenum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79ebb62-e2d7-49c3-99d4-7abb9a87131c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell if you have a single sensor experiment\n",
    "\n",
    "# Find the number of observations for each tilenum\n",
    "num_obs = []\n",
    "for i in range(num_unique_tilenum):\n",
    "    num_obs.append(len(obs_obs_grouped[i]))\n",
    "\n",
    "# Calculate the mean obs_obs for each tilenum\n",
    "mean_obs_obs = []\n",
    "for i in range(num_unique_tilenum):\n",
    "    mean_obs_obs.append(np.mean(obs_obs_grouped[i]))\n",
    "    \n",
    "# Calculate the std obs_obs for each tilenum\n",
    "std_obs_obs = []\n",
    "for i in range(num_unique_tilenum):\n",
    "    std_obs_obs.append(np.std(obs_obs_grouped[i]))    \n",
    "\n",
    "# Calculate the mean obs_fcst for each tilenum\n",
    "mean_obs_fcst = []\n",
    "for i in range(num_unique_tilenum):\n",
    "    mean_obs_fcst.append(np.mean(obs_fcst_grouped[i]))\n",
    "\n",
    "# Calculate the mean obs_ana for each tilenum\n",
    "mean_obs_ana = []\n",
    "for i in range(num_unique_tilenum):\n",
    "    mean_obs_ana.append(np.mean(obs_ana_grouped[i]))\n",
    "\n",
    "# Calculate the mean obs_minus_fcst for each tilenum\n",
    "mean_obs_minus_fcst = []\n",
    "for i in range(num_unique_tilenum):\n",
    "    mean_obs_minus_fcst.append(np.mean(obs_minus_fcst_grouped[i]))\n",
    "\n",
    "# Calculate the mean obs_minus_ana for each tilenum\n",
    "mean_obs_minus_ana = []\n",
    "for i in range(num_unique_tilenum):\n",
    "    mean_obs_minus_ana.append(np.mean(obs_minus_ana_grouped[i]))\n",
    "\n",
    "# Calculate the standard deviation of obs_minus_fcst for each tilenum\n",
    "std_obs_minus_fcst = []\n",
    "for i in range(num_unique_tilenum):\n",
    "    std_obs_minus_fcst.append(np.std(obs_minus_fcst_grouped[i]))\n",
    "\n",
    "# Calculate the standard deviation of obs_minus_ana for each tilenum\n",
    "std_obs_minus_ana = []\n",
    "for i in range(num_unique_tilenum):\n",
    "    std_obs_minus_ana.append(np.std(obs_minus_ana_grouped[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0168daf6-504a-42dc-96df-182709d653f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell if you have a single sensor experiment\n",
    "# Save all of the calculated values to a file\n",
    "np.savez(f'{expt_name}_{start_date_str}_{end_date_str}_obsfcstana_stats.npz',\n",
    "         unique_tilenum=unique_tilenum,\n",
    "         num_obs=num_obs,\n",
    "         mean_obs_obs=mean_obs_obs,\n",
    "         std_obs_obs=std_obs_obs,\n",
    "         mean_obs_fcst=mean_obs_fcst,\n",
    "         mean_obs_ana=mean_obs_ana,\n",
    "         mean_obs_minus_fcst=mean_obs_minus_fcst,\n",
    "         mean_obs_minus_ana=mean_obs_minus_ana,\n",
    "         std_obs_minus_fcst=std_obs_minus_fcst,\n",
    "         std_obs_minus_ana=std_obs_minus_ana,\n",
    "         lon_tilenum=lon_tilenum,\n",
    "         lat_tilenum=lat_tilenum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dd12de-e763-4497-8483-2d67763aae54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell if you have a multi-sensor experiment\n",
    "\n",
    "# Find the number of observations for each tilenum\n",
    "num_obs_smap = []\n",
    "num_obs_ascat = []\n",
    "for i in range(num_unique_tilenum):\n",
    "    num_obs_smap.append(len(obs_obs_grouped[i][obs_species_grouped[i] < 5]))\n",
    "    num_obs_ascat.append(len(obs_obs_grouped[i][obs_species_grouped[i] > 4]))\n",
    "\n",
    "#Calculate the mean of the observations for each tilenum\n",
    "mean_obs_smap = []\n",
    "mean_obs_ascat = []\n",
    "for i in range(num_unique_tilenum):\n",
    "    mean_obs_smap.append(np.mean(obs_obs_grouped[i][obs_species_grouped[i] < 5]))\n",
    "    mean_obs_ascat.append(np.mean(obs_obs_grouped[i][obs_species_grouped[i] > 4]))\n",
    "\n",
    "# Calculate the mean of the forecasts for each tilenum\n",
    "mean_fcst_smap = []\n",
    "mean_fcst_ascat = []\n",
    "for i in range(num_unique_tilenum):\n",
    "    mean_fcst_smap.append(np.mean(obs_fcst_grouped[i][obs_species_grouped[i] < 5]))\n",
    "    mean_fcst_ascat.append(np.mean(obs_fcst_grouped[i][obs_species_grouped[i] > 4]))\n",
    "\n",
    "# Calculate the mean of the analyses for each tilenum\n",
    "mean_ana_smap = []\n",
    "mean_ana_ascat = []\n",
    "for i in range(num_unique_tilenum):\n",
    "    mean_ana_smap.append(np.mean(obs_ana_grouped[i][obs_species_grouped[i] < 5]))\n",
    "    mean_ana_ascat.append(np.mean(obs_ana_grouped[i][obs_species_grouped[i] > 4]))\n",
    "\n",
    "# Calculate the mean of the obs minus fcst for each tilenum\n",
    "mean_obs_minus_fcst_smap = []\n",
    "mean_obs_minus_fcst_ascat = []\n",
    "for i in range(num_unique_tilenum):\n",
    "    mean_obs_minus_fcst_smap.append(np.mean(obs_minus_fcst_grouped[i][obs_species_grouped[i] < 5]))\n",
    "    mean_obs_minus_fcst_ascat.append(np.mean(obs_minus_fcst_grouped[i][obs_species_grouped[i] > 4]))\n",
    "\n",
    "# Calculate the mean of the obs minus ana for each tilenum\n",
    "mean_obs_minus_ana_smap = []\n",
    "mean_obs_minus_ana_ascat = []\n",
    "for i in range(num_unique_tilenum):\n",
    "    mean_obs_minus_ana_smap.append(np.mean(obs_minus_ana_grouped[i][obs_species_grouped[i] < 5]))\n",
    "    mean_obs_minus_ana_ascat.append(np.mean(obs_minus_ana_grouped[i][obs_species_grouped[i] > 4]))\n",
    "\n",
    "# Calculate the standard deviation of the obs_minus_fcst for each tilenum\n",
    "std_obs_minus_fcst_smap = []\n",
    "std_obs_minus_fcst_ascat = []\n",
    "for i in range(num_unique_tilenum):\n",
    "    std_obs_minus_fcst_smap.append(np.std(obs_minus_fcst_grouped[i][obs_species_grouped[i] < 5]))\n",
    "    std_obs_minus_fcst_ascat.append(np.std(obs_minus_fcst_grouped[i][obs_species_grouped[i] > 4]))\n",
    "\n",
    "# Calculate the standard deviation of the obs_minus_ana for each tilenum\n",
    "std_obs_minus_ana_smap = []\n",
    "std_obs_minus_ana_ascat = []\n",
    "for i in range(num_unique_tilenum):\n",
    "    std_obs_minus_ana_smap.append(np.std(obs_minus_ana_grouped[i][obs_species_grouped[i] < 5]))\n",
    "    std_obs_minus_ana_ascat.append(np.std(obs_minus_ana_grouped[i][obs_species_grouped[i] > 4]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffaab8a-e552-4534-a281-5d7dcf1a4a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell if you have a multi-sensor experiment\n",
    "# Save all the calculated values to a file\n",
    "np.savez(f'{expt_name}_{start_date_str}_{end_date_str}_obsfcstana_stats.npz',\n",
    "         unique_tilenum=unique_tilenum,\n",
    "         num_obs_smap=num_obs_smap,\n",
    "         num_obs_ascat=num_obs_ascat,\n",
    "         mean_obs_smap=mean_obs_smap,\n",
    "         mean_obs_ascat=mean_obs_ascat,\n",
    "         mean_fcst_smap=mean_fcst_smap,\n",
    "         mean_fcst_ascat=mean_fcst_ascat,\n",
    "         mean_ana_smap=mean_ana_smap,\n",
    "         mean_ana_ascat=mean_ana_ascat,\n",
    "         mean_obs_minus_fcst_smap=mean_obs_minus_fcst_smap,\n",
    "         mean_obs_minus_fcst_ascat=mean_obs_minus_fcst_ascat,\n",
    "         mean_obs_minus_ana_smap=mean_obs_minus_ana_smap,\n",
    "         mean_obs_minus_ana_ascat=mean_obs_minus_ana_ascat,\n",
    "         std_obs_minus_fcst_smap=std_obs_minus_fcst_smap,\n",
    "         std_obs_minus_fcst_ascat=std_obs_minus_fcst_ascat,\n",
    "         std_obs_minus_ana_smap=std_obs_minus_ana_smap,\n",
    "         std_obs_minus_ana_ascat=std_obs_minus_ana_ascat,\n",
    "         lon_tilenum=lon_tilenum,\n",
    "         lat_tilenum=lat_tilenum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaab4cd-2ad8-479b-8be1-b3055888b090",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    obarray = np.empty([num_unique_tilenum, 3])\n",
    "    obarray[:, 1] = lon_tilenum\n",
    "    obarray[:, 2] = lat_tilenum\n",
    "    obarray[:, 0] = num_obs_ascat\n",
    "    \n",
    "    plot_global(obarray,False,'Number of ASCAT Obs Assimilated','Total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ebd743-fb64-412d-956d-73dc595ce085",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-diag]",
   "language": "python",
   "name": "conda-env-.conda-diag-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
