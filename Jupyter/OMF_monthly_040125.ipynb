{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_name = 'LS_OLv8_M36'\n",
    "\n",
    "start_date = datetime(2020, 1, 2)\n",
    "end_date = datetime(2020, 1, 6)\n",
    "\n",
    "start_date_str = start_date.strftime('%Y%m%d')\n",
    "end_date_str = end_date.strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_obsfcstana_extend_datetime(path, file_name, printflag=False):\n",
    "    # Define precisions\n",
    "    int_precision = 'int32'\n",
    "    float_precision = 'float32'\n",
    "    logical_precision = 'int32'\n",
    "\n",
    "    # Initialize lists for outputs\n",
    "    date_time_list = []\n",
    "    obs_assim_list = []\n",
    "    obs_species_list = []\n",
    "    obs_tilenum_list = []\n",
    "    obs_lon_list = []\n",
    "    obs_lat_list = []\n",
    "    obs_obs_list = []\n",
    "    obs_obsvar_list = []\n",
    "    obs_fcst_list = []\n",
    "    obs_fcstvar_list = []\n",
    "    obs_ana_list = []\n",
    "    obs_anavar_list = []\n",
    "\n",
    "    machfmt = 'b'\n",
    "    file_ext = '.bin'\n",
    "    # Build full file paths (note: file already includes the path)\n",
    "    files = [os.path.join(root, file) \n",
    "             for root, dirs, files in os.walk(path) \n",
    "             for file in files if file.startswith(file_name) and file.endswith(file_ext)]\n",
    "\n",
    "    if printflag:\n",
    "        print(files)\n",
    "\n",
    "    mode = 'rb' if machfmt == 'b' else 'rl'\n",
    "\n",
    "    for file in files:\n",
    "        with open(file, mode) as ifp:  # file already includes the path\n",
    "            if printflag:\n",
    "                print('Reading file', file, '...')\n",
    "            \n",
    "            # Read header and time stamp data\n",
    "            _ = np.fromfile(ifp, int_precision, 1)  # fortran_tag\n",
    "            N_obs = int(np.fromfile(ifp, int_precision, 1))\n",
    "            # Read time components\n",
    "            year    = np.fromfile(ifp, int_precision, 1)\n",
    "            month   = np.fromfile(ifp, int_precision, 1)\n",
    "            day     = np.fromfile(ifp, int_precision, 1)\n",
    "            hour    = np.fromfile(ifp, int_precision, 1)\n",
    "            minute  = np.fromfile(ifp, int_precision, 1)\n",
    "            second  = np.fromfile(ifp, int_precision, 1)\n",
    "            dofyr   = np.fromfile(ifp, int_precision, 1)\n",
    "            pentad  = np.fromfile(ifp, int_precision, 1)\n",
    "            _ = np.fromfile(ifp, int_precision, 1)  # fortran_tag\n",
    "\n",
    "            # Create a single dictionary for the timestamp info and extend the list\n",
    "            date_time_tmp = {\n",
    "                'year': year,\n",
    "                'month': month,\n",
    "                'day': day,\n",
    "                'hour': hour,\n",
    "                'min': minute,\n",
    "                'sec': second,\n",
    "                'dofyr': dofyr,\n",
    "                'pentad': pentad\n",
    "            }\n",
    "            date_time_list.extend([date_time_tmp] * N_obs) \n",
    "\n",
    "            # Read observation assimilation flag\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            tmp_data = np.fromfile(ifp, logical_precision, N_obs)\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            # Vectorized conversion: nonzero becomes 1, else 0.\n",
    "            tmp_data2 = (tmp_data != 0).astype(np.int32).reshape(-1, 1)\n",
    "            obs_assim_list.append(tmp_data2)\n",
    "\n",
    "            # Read species information\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            obs_species_list.append(np.fromfile(ifp, int_precision, N_obs))\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            \n",
    "            # Read tile number information\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            obs_tilenum_list.append(np.fromfile(ifp, int_precision, N_obs))\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "\n",
    "            # Read longitude\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            obs_lon_list.append(np.fromfile(ifp, float_precision, N_obs))\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "\n",
    "            # Read latitude\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            obs_lat_list.append(np.fromfile(ifp, float_precision, N_obs))\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            \n",
    "            # Read observation value\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            obs_obs_list.append(np.fromfile(ifp, float_precision, N_obs))\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "\n",
    "            # Read observation variance\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            obs_obsvar_list.append(np.fromfile(ifp, float_precision, N_obs))\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "\n",
    "            # Read forecast value\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            obs_fcst_list.append(np.fromfile(ifp, float_precision, N_obs))\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "\n",
    "            # Read forecast variance\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            obs_fcstvar_list.append(np.fromfile(ifp, float_precision, N_obs))\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "\n",
    "            # Read analysis value\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            obs_ana_list.append(np.fromfile(ifp, float_precision, N_obs))\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "\n",
    "            # Read analysis variance\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            obs_anavar_list.append(np.fromfile(ifp, float_precision, N_obs))\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "\n",
    "    # After processing all files, concatenate lists into numpy arrays\n",
    "    obs_assim = np.concatenate(obs_assim_list) if obs_assim_list else np.array([])\n",
    "    obs_species = np.concatenate(obs_species_list) if obs_species_list else np.array([])\n",
    "    obs_tilenum = np.concatenate(obs_tilenum_list) if obs_tilenum_list else np.array([])\n",
    "    obs_lon = np.concatenate(obs_lon_list) if obs_lon_list else np.array([])\n",
    "    obs_lat = np.concatenate(obs_lat_list) if obs_lat_list else np.array([])\n",
    "    obs_obs = np.concatenate(obs_obs_list) if obs_obs_list else np.array([])\n",
    "    obs_obsvar = np.concatenate(obs_obsvar_list) if obs_obsvar_list else np.array([])\n",
    "    obs_fcst = np.concatenate(obs_fcst_list) if obs_fcst_list else np.array([])\n",
    "    obs_fcstvar = np.concatenate(obs_fcstvar_list) if obs_fcstvar_list else np.array([])\n",
    "    obs_ana = np.concatenate(obs_ana_list) if obs_ana_list else np.array([])\n",
    "    obs_anavar = np.concatenate(obs_anavar_list) if obs_anavar_list else np.array([])\n",
    "\n",
    "    return (date_time_list, obs_assim, obs_species, obs_tilenum, obs_lon, obs_lat, \n",
    "            obs_obs, obs_obsvar, obs_fcst, obs_fcstvar, obs_ana, obs_anavar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p3/6g36x17x60d12xdgb49ryq4r0000gr/T/ipykernel_23364/3426211478.py:40: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  N_obs = int(np.fromfile(ifp, int_precision, 1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tilenum values: 0\n"
     ]
    }
   ],
   "source": [
    "# Calculate the daily statistics in observation space\n",
    "\n",
    "# Define the path directory\n",
    "path = f'/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/land_sweeper/{expt_name}/output/SMAP_EASEv2_M36_GLOBAL/ana/ens_avg'\n",
    "\n",
    "# Define the common file name start\n",
    "file_name_start = f'{expt_name}.ens_avg.ldas_ObsFcstAna.'\n",
    "\n",
    "# Define the print flag\n",
    "printflag = False\n",
    "\n",
    "# Loop over the dates\n",
    "current_date = start_date\n",
    "\n",
    "while current_date <= end_date:\n",
    "    # Define the file name for the current date\n",
    "    file_name = file_name_start + current_date.strftime('%Y%m')\n",
    "    \n",
    "    # Call the read_obsfcstana function for the current file\n",
    "    date_time, obs_assim, species, tilenum, lon, lat, obs, obsvar, fcst, fcstvar, ana, anavar = read_obsfcstana_extend_datetime(path, file_name, printflag)\n",
    "\n",
    "    # Use obs_assim as a mask, obs_assim = 1 means assimilated\n",
    "    obs_assim = obs_assim.ravel()\n",
    "    obs = obs[obs_assim == 1]\n",
    "    species = species[obs_assim == 1]\n",
    "    tilenum = tilenum[obs_assim == 1]\n",
    "    lon = lon[obs_assim == 1]\n",
    "    lat = lat[obs_assim == 1]\n",
    "    fcst = fcst[obs_assim == 1]\n",
    "    ana = ana[obs_assim == 1]\n",
    "\n",
    "    # Initialize arrays\n",
    "    max_tilenum = 112573\n",
    "    max_speciesnum = 13\n",
    "\n",
    "    obs_cnt  = np.zeros((max_tilenum + 1, max_speciesnum + 1))\n",
    "    obs_sum  = np.zeros((max_tilenum + 1, max_speciesnum + 1))\n",
    "    obs2_sum = np.zeros((max_tilenum + 1, max_speciesnum + 1))\n",
    "    fcst_sum  = np.zeros((max_tilenum + 1, max_speciesnum + 1))\n",
    "    fcst2_sum = np.zeros((max_tilenum + 1, max_speciesnum + 1))\n",
    "    ana_sum  = np.zeros((max_tilenum + 1, max_speciesnum + 1))\n",
    "    ana2_sum = np.zeros((max_tilenum + 1, max_speciesnum + 1))\n",
    "    omf_sum  = np.zeros((max_tilenum + 1, max_speciesnum + 1))\n",
    "    omf2_sum = np.zeros((max_tilenum + 1, max_speciesnum + 1))\n",
    "    oma_sum  = np.zeros((max_tilenum + 1, max_speciesnum + 1))\n",
    "    oma2_sum = np.zeros((max_tilenum + 1, max_speciesnum + 1))\n",
    "\n",
    "\n",
    "    # Calculate the difference between the observation and forecast and observation and analysis\n",
    "    omf = obs - fcst\n",
    "    oma = obs - ana \n",
    "\n",
    "    # Find unique species values and their number\n",
    "    unique_species, counts = np.unique(species, return_counts=True)\n",
    "    num_unique_species = len(unique_species)\n",
    "\n",
    "    # Find unique tilenum values\n",
    "    unique_tilenum = np.unique(tilenum)\n",
    "\n",
    "    # Find the number of unique tilenum values\n",
    "    num_unique_tilenum = len(unique_tilenum)\n",
    "\n",
    "    # Print the number of unique tilenum values\n",
    "    print(f\"Number of unique tilenum values: {num_unique_tilenum}\")\n",
    "\n",
    "    # Sort the arrays based on tilenum\n",
    "    sort_indices = np.argsort(tilenum)\n",
    "    sorted_tilenum = tilenum[sort_indices]\n",
    "    sorted_species = species[sort_indices]\n",
    "    sorted_obs = obs[sort_indices]\n",
    "    sorted_fcst = fcst[sort_indices]\n",
    "    sorted_ana = ana[sort_indices]\n",
    "    sorted_omf = omf[sort_indices]\n",
    "    sorted_oma = oma[sort_indices]\n",
    "\n",
    "    # Find the unique tilenum values and their counts\n",
    "    unique_tilenum, counts = np.unique(sorted_tilenum, return_counts=True)\n",
    "\n",
    "    # Calculate the indices where the groups should be split\n",
    "    split_indices = np.cumsum(counts)[:-1]\n",
    "\n",
    "    # Split the sorted arrays based on the split indices\n",
    "    tilenum_tile = np.split(sorted_tilenum, split_indices)\n",
    "    species_tile = np.split(sorted_species, split_indices)\n",
    "    obs_tile = np.split(sorted_obs, split_indices)\n",
    "    fcst_tile = np.split(sorted_fcst, split_indices)\n",
    "    ana_tile = np.split(sorted_ana, split_indices)\n",
    "    omf_tile = np.split(sorted_omf, split_indices)\n",
    "    oma_tile = np.split(sorted_oma, split_indices)\n",
    "\n",
    "    # Loop over the unique tiles\n",
    "\n",
    "    for i in range(num_unique_tilenum):\n",
    "        tc = int(tilenum_tile[i][0])  # Current tile number\n",
    "\n",
    "        # Create a dictionary to store indices for each species in the current tile\n",
    "        species_indices_dict = {sc: np.where(species_tile[i] == sc)[0] for sc in unique_species}\n",
    "\n",
    "        for sc in unique_species:\n",
    "            species_indices = species_indices_dict[sc]\n",
    "\n",
    "            if len(species_indices) > 0:\n",
    "                sc = int(sc)  # Current species number\n",
    "                obs_cnt[tc, sc] += len(species_indices)\n",
    "                obs_sum[tc, sc] += np.sum(obs_tile[i][species_indices])\n",
    "                obs2_sum[tc, sc] += np.sum(obs_tile[i][species_indices]**2)\n",
    "                fcst_sum[tc, sc] += np.sum(fcst_tile[i][species_indices])\n",
    "                fcst2_sum[tc, sc] += np.sum(fcst_tile[i][species_indices]**2)\n",
    "                ana_sum[tc, sc] += np.sum(ana_tile[i][species_indices])\n",
    "                ana2_sum[tc, sc] += np.sum(ana_tile[i][species_indices]**2)\n",
    "                omf_sum[tc, sc] += np.sum(omf_tile[i][species_indices])\n",
    "                omf2_sum[tc, sc] += np.sum(omf_tile[i][species_indices]**2)\n",
    "                oma_sum[tc, sc] += np.sum(oma_tile[i][species_indices])\n",
    "                oma2_sum[tc, sc] += np.sum(oma_tile[i][species_indices]**2)\n",
    "\n",
    "\n",
    "    # Write this values out to a npz file\n",
    "    np.savez(f'{path}/{expt_name}.ens_avg.ldas_ObsFcstAna.summed.{current_date.strftime(\"%Y%m\")}.npz',\n",
    "             obs_cnt=obs_cnt, obs_sum=obs_sum, obs2_sum=obs2_sum, fcst_sum=fcst_sum, fcst2_sum=fcst2_sum, ana_sum=ana_sum, ana2_sum=ana2_sum, omf_sum=omf_sum, omf2_sum=omf2_sum, oma_sum=oma_sum, oma2_sum=oma2_sum,\n",
    "             num_unique_tilenum=num_unique_tilenum, num_unique_species=num_unique_species)\n",
    "\n",
    "    current_date += relativedelta(months=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0]\n",
      "[9662196]\n"
     ]
    }
   ],
   "source": [
    "# Investigate obs_assim\n",
    "print(obs_assim[:20])\n",
    "\n",
    "# Find the unique values in obs_assim, and their counts\n",
    "unique_obs_assim, counts = np.unique(obs_assim, return_counts=True)\n",
    "\n",
    "# Print the unique values and their counts\n",
    "print(unique_obs_assim)\n",
    "print(counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
