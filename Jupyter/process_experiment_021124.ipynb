{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f24bbef7-9345-4bf8-b845-3bb525e9c399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "\n",
    "from my_functions import read_obsfcstana_extend_datetime\n",
    "from my_functions import read_obsfcstana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "566e4a81-b8a0-449b-907e-66012530f49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expt_name = 'DAv7_M36_ASCAT_type_13_no_catdef_fp', 'DAv7_M36_ASCAT_type_2_fp_precip', 'DAv7_M36_ASCAT_type_13_test_catdef'\n",
    "expt_name = 'DAv7_M36_ASCAT_type_2_fp_precip'\n",
    "\n",
    "start_date = datetime(2015, 4, 1)\n",
    "end_date = datetime(2015, 4, 20)\n",
    "\n",
    "start_date_str = start_date.strftime('%Y%m%d')\n",
    "end_date_str = end_date.strftime('%Y%m%d')\n",
    "\n",
    "# filename = f\"{start_date_str}_{end_date_str}.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7ee0d5c-5e64-4e97-bebb-90cfe8d2b7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "years =  ['2015']\n"
     ]
    }
   ],
   "source": [
    "# Produce with extended date_time\n",
    "# Define the list of years\n",
    "years = [str(year) for year in range(start_date.year, end_date.year + 1)]\n",
    "print('years = ', years)\n",
    "\n",
    "# Define the common file name start\n",
    "file_name_start = expt_name+'.ens_avg.ldas_ObsFcstAna.20'\n",
    "\n",
    "# Define the print flag\n",
    "printflag = False\n",
    "\n",
    "# Loop over the years\n",
    "for i in range(len(years)-1):\n",
    "    # Define the current and next year\n",
    "    current_year = years[i]\n",
    "    next_year = years[i+1]\n",
    "    # Define the list of paths\n",
    "    paths = []\n",
    "    for month in range(4, 13):\n",
    "        path = f'/discover/nobackup/amfox/Experiments/{expt_name}/{expt_name}/output/SMAP_EASEv2_M36_GLOBAL/ana/ens_avg/Y{current_year}/M{month:02d}'\n",
    "        paths.append(path)\n",
    "\n",
    "    for month in range(1, 4):\n",
    "        path = f'/discover/nobackup/amfox/Experiments/{expt_name}/{expt_name}/output/SMAP_EASEv2_M36_GLOBAL/ana/ens_avg/Y{next_year}/M{month:02d}'\n",
    "        paths.append(path)\n",
    "    \n",
    "    # Initialize lists to store the returned values\n",
    "    date_times = []\n",
    "    obs_species_list = []\n",
    "    obs_tilenum_list = []\n",
    "    obs_lon_list = []\n",
    "    obs_lat_list = []\n",
    "    obs_obs_list = []\n",
    "    obs_fcst_list = []\n",
    "    obs_ana_list = []\n",
    "    \n",
    "    # Loop over the paths for the current year\n",
    "    for path in paths:\n",
    "        # Print the current path\n",
    "        print(\"Current path:\", path)\n",
    "\n",
    "        # Call the read_obsfcstana function for the current path\n",
    "        date_time, obs_species, obs_tilenum, obs_lon, obs_lat, obs_obs, obs_obsvar, obs_fcst, obs_fcstvar, obs_ana, obs_anavar = read_obsfcstana_extend_datetime(path, file_name_start, printflag)\n",
    "        \n",
    "        # Append the returned values to the lists\n",
    "        date_times.append(date_time)\n",
    "        obs_species_list.append(obs_species)\n",
    "        obs_tilenum_list.append(obs_tilenum)\n",
    "        obs_lon_list.append(obs_lon)\n",
    "        obs_lat_list.append(obs_lat)\n",
    "        obs_obs_list.append(obs_obs)\n",
    "        obs_fcst_list.append(obs_fcst)\n",
    "        obs_ana_list.append(obs_ana)\n",
    "    \n",
    "    # Combine the returned values from all paths\n",
    "    date_time_out = np.concatenate(date_times)\n",
    "    obs_species_out = np.concatenate(obs_species_list)\n",
    "    obs_tilenum_out = np.concatenate(obs_tilenum_list)\n",
    "    obs_lon_out = np.concatenate(obs_lon_list)\n",
    "    obs_lat_out = np.concatenate(obs_lat_list)\n",
    "    obs_obs_out = np.concatenate(obs_obs_list)\n",
    "    obs_fcst_out = np.concatenate(obs_fcst_list)\n",
    "    obs_ana_out = np.concatenate(obs_ana_list)\n",
    "    \n",
    "    # Save the returned values to a file including the current year in the file name\n",
    "    np.savez(f'{expt_name}_{start_date_str}_{end_date_str}_obsfcstana_extend_datetime_{current_year}.npz',\n",
    "             date_time=date_time_out,\n",
    "             obs_species=obs_species_out,\n",
    "             obs_tilenum=obs_tilenum_out,\n",
    "             obs_lon=obs_lon_out,\n",
    "             obs_lat=obs_lat_out,\n",
    "             obs_obs=obs_obs_out,\n",
    "             obs_fcst=obs_fcst_out,\n",
    "             obs_ana=obs_ana_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19d4cba4-4887-4a64-8f56-d0663be35dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/discover/nobackup/amfox/Experiments/DAv7_M36_ASCAT_type_2_fp_precip/DAv7_M36_ASCAT_type_2_fp_precip/output/SMAP_EASEv2_M36_GLOBAL/cat/ens_avg/Y2015/M04\n",
      "working on sfmc_increment_concat\n",
      "working on rzmc_increment_concat\n",
      "working on prmc_increment_concat\n"
     ]
    }
   ],
   "source": [
    "# Directory path to search for NetCDF files\n",
    "root_directory = f'/discover/nobackup/amfox/Experiments/{expt_name}/{expt_name}/output/SMAP_EASEv2_M36_GLOBAL/cat/ens_avg/'\n",
    "\n",
    "# Initialize an empty list to store the calculated sfmc_increment values\n",
    "sfmc_increment_list = []\n",
    "rzmc_increment_list = []\n",
    "prmc_increment_list = []\n",
    "\n",
    "time_stamp_list = []\n",
    "\n",
    "current_date = start_date\n",
    "\n",
    "while current_date <= end_date:\n",
    "    year_month_directory = os.path.join(root_directory, \n",
    "                                        f\"Y{current_date.year}\", \n",
    "                                        f\"M{current_date.month:02d}\")\n",
    "    print(year_month_directory)\n",
    "    for filename in sorted(os.listdir(year_month_directory)):\n",
    "        if filename.endswith('.nc4') and not filename.endswith('z.nc4') and filename.startswith(f'{expt_name}.inst3_1d_lndfcstana_Nt.2'):\n",
    "            # Construct the full file path\n",
    "            file_path = os.path.join(year_month_directory, filename)\n",
    "            # Open the NetCDF file using xarray\n",
    "            ds = xr.open_dataset(file_path)           \n",
    "\n",
    "            # Extract time_stamp\n",
    "            time_stamp = ds['time_stamp']\n",
    "            \n",
    "            time_stamp_list.append(time_stamp)\n",
    "            \n",
    "            # Extract the SFMC_ANA and SFMC_FCST variables\n",
    "            sfmc_ana = ds['SFMC_ANA']\n",
    "            sfmc_fcst = ds['SFMC_FCST']\n",
    "            rzmc_ana = ds['RZMC_ANA']\n",
    "            rzmc_fcst = ds['RZMC_FCST']\n",
    "            prmc_ana = ds['PRMC_ANA']\n",
    "            prmc_fcst = ds['PRMC_FCST']            \n",
    "            \n",
    "            # Calculate the sfmc_increment\n",
    "            sfmc_increment = sfmc_ana - sfmc_fcst\n",
    "            rzmc_increment = rzmc_ana - rzmc_fcst\n",
    "            prmc_increment = prmc_ana - prmc_fcst\n",
    "            \n",
    "            # Append the sfmc_increment values to the list\n",
    "            sfmc_increment_list.append(sfmc_increment)\n",
    "            rzmc_increment_list.append(rzmc_increment)\n",
    "            prmc_increment_list.append(prmc_increment)\n",
    "            \n",
    "            # Close the NetCDF file\n",
    "            ds.close()\n",
    "            \n",
    "    current_date += relativedelta(months=1)\n",
    "\n",
    "# Concatenate the sfmc_increment values along the time dimension\n",
    "print('working on sfmc_increment_concat')\n",
    "sfmc_increment_concat = xr.concat(sfmc_increment_list, dim='time')\n",
    "print('working on rzmc_increment_concat')\n",
    "rzmc_increment_concat = xr.concat(rzmc_increment_list, dim='time')\n",
    "print('working on prmc_increment_concat')\n",
    "prmc_increment_concat = xr.concat(prmc_increment_list, dim='time')\n",
    "\n",
    "time_stamp_concat = xr.concat(time_stamp_list, dim='time')\n",
    "\n",
    "# Save both the concatenated sfmc_increment and rzmc_increment values to a new npsavez file\n",
    "np.savez(f'{expt_name}_{start_date_str}_{end_date_str}_increments_concat.npz',\n",
    "         time_stamp_concat=time_stamp_concat,\n",
    "         sfmc_increment_concat=sfmc_increment_concat,\n",
    "         rzmc_increment_concat=rzmc_increment_concat, \n",
    "         prmc_increment_concat=prmc_increment_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "336c5f00-27da-49ad-86de-ca63ee3654a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean sfmc_increment for each tile along the time dimension\n",
    "mean_sfmc_increment = []\n",
    "std_sfmc_increment = []\n",
    "mean_rzmc_increment = []\n",
    "std_rzmc_increment = []\n",
    "mean_prmc_increment = []\n",
    "std_prmc_increment = []\n",
    "\n",
    "for i in range(len(sfmc_increment_concat['tile'])):\n",
    "    mean_sfmc_increment.append(np.mean(sfmc_increment_concat[:, i]))\n",
    "    std_sfmc_increment.append(np.std(sfmc_increment_concat[:, i]))\n",
    "    mean_rzmc_increment.append(np.mean(rzmc_increment_concat[:, i]))\n",
    "    std_rzmc_increment.append(np.std(rzmc_increment_concat[:, i]))\n",
    "    mean_prmc_increment.append(np.mean(prmc_increment_concat[:, i]))\n",
    "    std_prmc_increment.append(np.std(prmc_increment_concat[:,i]))\n",
    "\n",
    "# Save a new npsavez file\n",
    "np.savez(f'{expt_name}_{start_date_str}_{end_date_str}_increment_stats.npz',\n",
    "        mean_sfmc_increment=mean_sfmc_increment,\n",
    "        std_sfmc_increment=std_sfmc_increment,\n",
    "        mean_rzmc_increment=mean_rzmc_increment,\n",
    "        std_rzmc_increment=std_rzmc_increment,\n",
    "        mean_prmc_increment=mean_prmc_increment,\n",
    "        std_prmc_increment=std_prmc_increment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb2b1232-beb1-47d9-94e0-77f031e62c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean sfmc_increment along the tile dimension\n",
    "ts_mean_sfmc_increment = []\n",
    "ts_std_sfmc_increment = []\n",
    "ts_mean_rzmc_increment = []\n",
    "ts_std_rzmc_increment = []\n",
    "ts_mean_prmc_increment = []\n",
    "ts_std_prmc_increment = []\n",
    "\n",
    "for i in range(len(sfmc_increment_concat['time'])):\n",
    "    ts_mean_sfmc_increment.append(np.mean(sfmc_increment_concat[:, i]))\n",
    "    ts_std_sfmc_increment.append(np.std(sfmc_increment_concat[:, i]))\n",
    "    ts_mean_rzmc_increment.append(np.mean(rzmc_increment_concat[:, i]))\n",
    "    ts_std_rzmc_increment.append(np.std(rzmc_increment_concat[:, i]))\n",
    "    ts_mean_prmc_increment.append(np.mean(prmc_increment_concat[:, i]))\n",
    "    ts_std_prmc_increment.append(np.std(prmc_increment_concat[:,i]))\n",
    "\n",
    "# Save a new npsavez file\n",
    "np.savez(f'{expt_name}_{start_date_str}_{end_date_str}_increment_timeseries.npz',\n",
    "        ts_mean_sfmc_increment=ts_mean_sfmc_increment,\n",
    "        ts_std_sfmc_increment=ts_std_sfmc_increment,\n",
    "        ts_mean_rzmc_increment=ts_mean_rzmc_increment,\n",
    "        ts_std_rzmc_increment=ts_std_rzmc_increment,\n",
    "        ts_mean_prmc_increment=ts_mean_prmc_increment,\n",
    "        ts_std_prmc_increment=ts_std_prmc_increment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd802bd1-0e11-4c44-b083-6a22d2b2b160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_name =  DAv7_M36_ASCAT_type_2_fp_precip.ens_avg.ldas_ObsFcstAna.20150401\n"
     ]
    }
   ],
   "source": [
    "# Define the path directory\n",
    "path_dir = f'/discover/nobackup/amfox/Experiments/{expt_name}/{expt_name}/output/SMAP_EASEv2_M36_GLOBAL/ana/ens_avg'\n",
    "\n",
    "# Define the common file name start\n",
    "file_name_start = f'{expt_name}.ens_avg.ldas_ObsFcstAna.'\n",
    "\n",
    "# Define the print flag\n",
    "printflag = False\n",
    "\n",
    "# Initialize lists to store the mean values for each variable and the dates\n",
    "obs_obs_mean_list = []\n",
    "obs_fcst_mean_list = []\n",
    "obs_ana_mean_list = []\n",
    "omf_mean_list = []\n",
    "oma_mean_list = []\n",
    "dates_list = []\n",
    "omf_max_list = []\n",
    "omf_std_list = []\n",
    "oma_std_list = []\n",
    "\n",
    "# Define the start and end dates\n",
    "# start_date = datetime.strptime('20150401', '%Y%m%d')\n",
    "# end_date = datetime.strptime('20210331', '%Y%m%d')\n",
    "\n",
    "# Loop over the dates\n",
    "current_date = start_date\n",
    "while current_date <= end_date:\n",
    "    # Define the file name for the current date\n",
    "    file_name = file_name_start + current_date.strftime('%Y%m%d')\n",
    "    if file_name[-4:] == '0401':\n",
    "        print('file_name = ', file_name)\n",
    "    \n",
    "    # Call the read_obsfcstana function for the current file\n",
    "    date_time, obs_species, obs_tilenum, obs_lon, obs_lat, obs_obs, obs_obsvar, obs_fcst, obs_fcstvar, obs_ana, obs_anavar = read_obsfcstana(path_dir, file_name, printflag)\n",
    "\n",
    "    # Convert the lists to numpy arrays\n",
    "    obs_obs = np.array(obs_obs)\n",
    "    obs_fcst = np.array(obs_fcst)\n",
    "    obs_ana = np.array(obs_ana)\n",
    "    # obs_obs = np.array(obs_obs[obs_species > 4])\n",
    "    # obs_fcst = np.array(obs_fcst[obs_species > 4])\n",
    "    # obs_ana = np.array(obs_ana[obs_species > 4])\n",
    "    \n",
    "    # Calculate the mean values for the variables\n",
    "    obs_obs_mean = np.mean(obs_obs)\n",
    "    obs_fcst_mean = np.mean(obs_fcst)\n",
    "    obs_ana_mean = np.mean(obs_ana)\n",
    "    omf_mean = np.mean(obs_obs - obs_fcst)\n",
    "    oma_mean = np.mean(obs_obs - obs_ana)\n",
    "    # Calculate the maximum absolute difference between obs_obs and obs_fcst\n",
    "    if obs_fcst.size > 0 and obs_obs.size > 0 and obs_fcst.shape == obs_obs.shape:\n",
    "        omf_max = np.max(abs(obs_obs - obs_fcst))\n",
    "    else:\n",
    "        omf_max = np.nan\n",
    "        print('Current date = ', current_date)\n",
    "    omf_std = np.std(obs_obs - obs_fcst)\n",
    "    oma_std = np.std(obs_obs - obs_ana)\n",
    "\n",
    "\n",
    "    # Append the mean values to the lists\n",
    "    obs_obs_mean_list.append(obs_obs_mean)\n",
    "    obs_fcst_mean_list.append(obs_fcst_mean)\n",
    "    obs_ana_mean_list.append(obs_ana_mean)\n",
    "    omf_mean_list.append(omf_mean)\n",
    "    oma_mean_list.append(oma_mean)\n",
    "    omf_max_list.append(omf_max)\n",
    "    omf_std_list.append(omf_std)\n",
    "    oma_std_list.append(oma_std)\n",
    "    \n",
    "    # Append the current date to the dates list\n",
    "    dates_list.append(current_date.strftime('%Y%m%d'))\n",
    "\n",
    "    # Increment the current date by one day\n",
    "    current_date += timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd5ce751-bef0-4b2c-be7e-7b172c2ad523",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(f'{expt_name}_{start_date_str}_{end_date_str}_OmF_ts.npz',\n",
    "         dates_list=dates_list,\n",
    "         obs_obs_mean_list=obs_obs_mean_list,\n",
    "         obs_fcst_mean_list=obs_fcst_mean_list,\n",
    "         obs_ana_mean_list=obs_ana_mean_list,\n",
    "         omf_mean_list=omf_mean_list,\n",
    "         oma_mean_list=oma_mean_list,\n",
    "         omf_max_list=omf_max_list,\n",
    "         omf_std_list=omf_std_list,\n",
    "         oma_std_list=oma_std_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e14ead0-235c-4f65-8507-3f976411a54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/discover/nobackup/amfox/Experiments/DAv7_M36_ASCAT_type_2_fp_precip/DAv7_M36_ASCAT_type_2_fp_precip/output/SMAP_EASEv2_M36_GLOBAL/cat/ens_avg/Y2015/M04\n"
     ]
    }
   ],
   "source": [
    "root_directory = f'/discover/nobackup/amfox/Experiments/{expt_name}/{expt_name}/output/SMAP_EASEv2_M36_GLOBAL/cat/ens_avg'\n",
    "\n",
    "sm_surface_list = []\n",
    "sm_rootzone_list = []\n",
    "sm_profile_list = []\n",
    "precipitation_total_surface_flux_list = []\n",
    "vegetation_greenness_fraction_list = []\n",
    "leaf_area_index_list = []\n",
    "time_stamp_list = []\n",
    "\n",
    "current_date = start_date\n",
    "\n",
    "while current_date <= end_date:\n",
    "    year_month_directory = os.path.join(root_directory, \n",
    "                                        f\"Y{current_date.year}\", \n",
    "                                        f\"M{current_date.month:02d}\")\n",
    "    print(year_month_directory)\n",
    "    for filename in sorted(os.listdir(year_month_directory)):\n",
    "        if filename.endswith('.nc4') and not filename.endswith('z.nc4') and filename.startswith(f'{expt_name}.SMAP_L4_SM_gph.2'):\n",
    "            file_path = os.path.join(year_month_directory, filename)\n",
    "            ds = xr.open_dataset(file_path)\n",
    "            \n",
    "            # Extract time_stamp\n",
    "            time_stamp = ds['time_stamp']\n",
    "            \n",
    "            sm_surface = ds['sm_surface']\n",
    "            sm_rootzone = ds['sm_rootzone']\n",
    "            sm_profile = ds['sm_profile']\n",
    "            precipitation_total_surface_flux = ds['precipitation_total_surface_flux']\n",
    "            vegetation_greenness_fraction = ds['vegetation_greenness_fraction']\n",
    "            leaf_area_index = ds['leaf_area_index']\n",
    "                       \n",
    "            time_stamp_list.append(time_stamp)    \n",
    "            sm_surface_list.append(sm_surface)\n",
    "            sm_rootzone_list.append(sm_rootzone)\n",
    "            sm_profile_list.append(sm_profile)\n",
    "            precipitation_total_surface_flux_list.append(precipitation_total_surface_flux)\n",
    "            vegetation_greenness_fraction_list.append(vegetation_greenness_fraction)\n",
    "            leaf_area_index_list.append(leaf_area_index)\n",
    "\n",
    "            ds.close()\n",
    "    current_date += relativedelta(months=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca07a6b8-5b53-4090-91a9-965a16a0599f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on sm_surface_concat\n",
      "working on sm_rootzone_concat\n",
      "working on sm_profile_concat\n",
      "working on precipitation_total_surface_flux_concat\n",
      "working on vegetation_greenness_fraction_concat\n",
      "working on leaf_area_index_concat\n",
      "working on time_stamp_concat\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the sfmc_increment values along the time dimension\n",
    "print('working on sm_surface_concat')\n",
    "sm_surface_concat = xr.concat(sm_surface_list, dim='time')\n",
    "print('working on sm_rootzone_concat')\n",
    "sm_rootzone_concat = xr.concat(sm_rootzone_list, dim='time')\n",
    "print('working on sm_profile_concat')\n",
    "sm_profile_concat = xr.concat(sm_profile_list, dim='time')\n",
    "print('working on precipitation_total_surface_flux_concat')\n",
    "precipitation_total_surface_flux_concat = xr.concat(precipitation_total_surface_flux_list, dim='time')\n",
    "print('working on vegetation_greenness_fraction_concat')\n",
    "vegetation_greenness_fraction_concat = xr.concat(vegetation_greenness_fraction_list, dim='time')\n",
    "print('working on leaf_area_index_concat')\n",
    "leaf_area_index_concat = xr.concat(leaf_area_index_list, dim='time')\n",
    "print('working on time_stamp_concat')\n",
    "time_stamp_concat = xr.concat(time_stamp_list, dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84d254c5-a209-4123-bd05-fea2fbedb7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(f'{expt_name}_{start_date_str}_{end_date_str}_SMAP_L4_SM_gph_concat.npz',\n",
    "         sm_surface_concat=sm_surface_concat,\n",
    "         sm_rootzone_concat=sm_rootzone_concat,\n",
    "         sm_profile_concat=sm_profile_concat,\n",
    "         precipitation_total_surface_flux_concat=precipitation_total_surface_flux_concat,\n",
    "         vegetation_greenness_fraction_concat=vegetation_greenness_fraction_concat,\n",
    "         leaf_area_index_concat=leaf_area_index_concat,\n",
    "         time_stamp_concat=time_stamp_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41f92b91-813e-41ff-aaca-30139e4205f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean, etc  for each tile along the time dimension\n",
    "mean_sm_surface = []\n",
    "std_sm_surface = []\n",
    "mean_sm_rootzone = []\n",
    "std_sm_rootzone = []\n",
    "mean_sm_profile = []\n",
    "std_sm_profile = []\n",
    "mean_precipitation_total_surface_flux = []\n",
    "mean_vegetation_greenness_fraction = []\n",
    "max_vegetation_greenness_fraction = []\n",
    "mean_leaf_area_index = []\n",
    "max_leaf_area_index = []\n",
    "\n",
    "for i in range(len(sm_surface_concat['tile'])):\n",
    "    mean_sm_surface.append(np.mean(sm_surface_concat[:, i]))\n",
    "    std_sm_surface.append(np.std(sm_surface_concat[:, i]))\n",
    "    mean_sm_rootzone.append(np.mean(sm_rootzone_concat[:, i]))\n",
    "    std_sm_rootzone.append(np.std(sm_rootzone_concat[:, i]))\n",
    "    mean_sm_profile.append(np.mean(sm_profile_concat[:, i]))\n",
    "    std_sm_profile.append(np.std(sm_profile_concat[:, i]))\n",
    "    mean_precipitation_total_surface_flux.append(np.mean(precipitation_total_surface_flux_concat[:, i]))\n",
    "    mean_vegetation_greenness_fraction.append(np.mean(vegetation_greenness_fraction_concat[:, i]))\n",
    "    max_vegetation_greenness_fraction.append(np.max(vegetation_greenness_fraction_concat[:, i]))\n",
    "    mean_leaf_area_index.append(np.mean(leaf_area_index_concat[:, i]))\n",
    "    max_leaf_area_index.append(np.max(leaf_area_index_concat[:, i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97e0408d-cc58-4d8d-8d52-3762ac89bfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save both the concatenated sfmc_increment and rzmc_increment values to a new npsavez file\n",
    "np.savez(f'{expt_name}_{start_date_str}_{end_date_str}_SMAP_L4_SM_gph_stats.npz', \n",
    "         mean_sm_surface=mean_sm_surface,\n",
    "         std_sm_surface=std_sm_surface,\n",
    "         mean_sm_rootzone=mean_sm_rootzone,\n",
    "         std_sm_rootzone=std_sm_rootzone,\n",
    "         mean_sm_profile=mean_sm_profile,\n",
    "         std_sm_profile=std_sm_profile,\n",
    "         mean_precipitation_total_surface_flux=mean_precipitation_total_surface_flux,\n",
    "         mean_vegetation_greenness_fraction=mean_vegetation_greenness_fraction,\n",
    "         max_vegetation_greenness_fraction=max_vegetation_greenness_fraction,\n",
    "         mean_leaf_area_index=mean_leaf_area_index,\n",
    "         max_leaf_area_index=max_leaf_area_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b977352e-1622-4e8e-9f48-f48d788d38aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean, etc for each time step along the tile dimension\n",
    "ts_mean_sm_surface = []\n",
    "ts_std_sm_surface = []\n",
    "ts_mean_sm_rootzone = []\n",
    "ts_std_sm_rootzone = []\n",
    "ts_mean_sm_profile = []\n",
    "ts_std_sm_profile = []\n",
    "ts_mean_precipitation_total_surface_flux = []\n",
    "ts_mean_vegetation_greenness_fraction = []\n",
    "ts_max_vegetation_greenness_fraction = []\n",
    "ts_mean_leaf_area_index = []\n",
    "ts_max_leaf_area_index = []\n",
    "\n",
    "for i in range(len(sm_surface_concat['time'])):\n",
    "    ts_mean_sm_surface.append(np.mean(sm_surface_concat[i, :]))\n",
    "    ts_std_sm_surface.append(np.std(sm_surface_concat[i, :]))\n",
    "    ts_mean_sm_rootzone.append(np.mean(sm_rootzone_concat[i, :]))\n",
    "    ts_std_sm_rootzone.append(np.std(sm_rootzone_concat[i, :]))\n",
    "    ts_mean_sm_profile.append(np.mean(sm_profile_concat[i, :]))\n",
    "    ts_std_sm_profile.append(np.std(sm_profile_concat[i, :]))\n",
    "    ts_mean_precipitation_total_surface_flux.append(np.mean(precipitation_total_surface_flux_concat[i, :]))\n",
    "    ts_mean_vegetation_greenness_fraction.append(np.mean(vegetation_greenness_fraction_concat[i, :]))\n",
    "    ts_max_vegetation_greenness_fraction.append(np.max(vegetation_greenness_fraction_concat[i, :]))\n",
    "    ts_mean_leaf_area_index.append(np.mean(leaf_area_index_concat[i, :]))\n",
    "    ts_max_leaf_area_index.append(np.max(leaf_area_index_concat[i, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c920908-ebf0-46bb-b70f-bbd60e6745cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the time series to a new npsavez file\n",
    "np.savez(f'{expt_name}_{start_date_str}_{end_date_str}_SMAP_L4_SM_gph_timeseries.npz', \n",
    "         ts_mean_sm_surface=ts_mean_sm_surface,\n",
    "         ts_std_sm_surface=ts_std_sm_surface,\n",
    "         ts_mean_sm_rootzone=ts_mean_sm_rootzone,\n",
    "         ts_std_sm_rootzone=ts_std_sm_rootzone,\n",
    "         ts_mean_sm_profile=ts_mean_sm_profile,\n",
    "         ts_std_sm_profile=ts_std_sm_profile,\n",
    "         ts_mean_precipitation_total_surface_flux=ts_mean_precipitation_total_surface_flux,\n",
    "         ts_mean_vegetation_greenness_fraction=ts_mean_vegetation_greenness_fraction,\n",
    "         ts_max_vegetation_greenness_fraction=ts_max_vegetation_greenness_fraction,\n",
    "         ts_mean_leaf_area_index=ts_mean_leaf_area_index,\n",
    "         ts_max_leaf_area_index=ts_max_leaf_area_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab4c31c-3925-431e-8871-9b98f823bfbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-diag]",
   "language": "python",
   "name": "conda-env-.conda-diag-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
