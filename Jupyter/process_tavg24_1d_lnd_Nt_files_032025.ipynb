{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab9df06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from dask import compute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a614ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the root directory and experiment name\n",
    "expt_name = 'snow_LS_OLv8_M36'\n",
    "root_directory = f'/discover/nobackup/amfox/Experiments/snow_M21C_test/{expt_name}/output/SMAP_EASEv2_M36_GLOBAL/cat/ens0000'\n",
    "\n",
    "# Define the start and end dates\n",
    "start_date = datetime(2003, 1, 1)\n",
    "end_date = datetime(2004, 1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed4b89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Find all matching files using glob ---\n",
    "file_pattern = os.path.join(\n",
    "    root_directory,\n",
    "    'Y*',\n",
    "    'M*',\n",
    "    f'{expt_name}.tavg24_1d_lnd_Nt.*.nc4'\n",
    ")\n",
    "\n",
    "all_files = sorted(glob.glob(file_pattern))\n",
    "\n",
    "# print the first 5 files, one per line\n",
    "for file in all_files[:5]:\n",
    "    print(file)\n",
    "\n",
    "# --- Parse date from filenames like:\n",
    "# snow_LS_OLv8_M36.tavg24_1d_lnd_Nt.20030101_1200z.nc4\n",
    "selected_files = []\n",
    "for file in all_files:\n",
    "    basename = os.path.basename(file)\n",
    "    try:\n",
    "        date_str = basename.split('.')[-2].split('_')[0]  # '20030101' just before the '_1200z.nc4'\n",
    "        file_date = datetime.strptime(date_str, '%Y%m%d')\n",
    "        if start_date <= file_date <= end_date:\n",
    "            selected_files.append(file)\n",
    "    except Exception as e:\n",
    "        continue\n",
    "\n",
    "# --- Load all selected datasets using nested combine with explicit concat_dim ---\n",
    "print(f\"Loading {len(selected_files)} files\")\n",
    "combined_ds = xr.open_mfdataset(\n",
    "    selected_files,\n",
    "    combine='nested',\n",
    "    concat_dim='time',\n",
    "    parallel=True,  # Enable parallel processing with Dask\n",
    "    engine='netcdf4',\n",
    "    chunks={}\n",
    ")\n",
    "\n",
    "print('Done loading files.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023d809b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the variables to be extracted\n",
    "variables = {\n",
    "    'sm_surface': 'SFMC',\n",
    "    'sm_rootzone': 'RZMC',\n",
    "    'sm_profile': 'PRMC',\n",
    "    'precipitation_total_surface_flux': 'PRECTOTCORRLAND',\n",
    "    'vegetation_greenness_fraction': 'GRN',\n",
    "    'leaf_area_index': 'LAI',\n",
    "    'snow_mass': 'SNOMASLAND',\n",
    "    'surface_temperature_of_land_incl_snow': 'TSURFLAND',\n",
    "    'soil_temperature_layer_1': 'TSOIL1',\n",
    "    'snowfall_land': 'PRECSNOCORRLAND',\n",
    "    'snow_depth_within_snow_covered_area_fraction_on_land': 'SNODPLAND',\n",
    "    'snowpack_evaporation_latent_heat_flux_on_land': 'LHLANDSBLN',\n",
    "    'overland_runoff_including_throughflow': 'RUNSURFLAND',\n",
    "    'baseflow_flux_land': 'BASEFLOWLAND',\n",
    "    'snowmelt_flux_land': 'SMLAND',\n",
    "    'total_evaporation_land': 'EVLAND',\n",
    "    'net_shortwave_flux_land': 'SWLAND',\n",
    "    'total_water_storage_land': 'TWLAND',\n",
    "    'fractional_area_of_snow_on_land': 'FRLANDSNO'  # New variable added\n",
    "}\n",
    "\n",
    "# Initialize dictionaries to store results\n",
    "results = {var: {} for var in variables}\n",
    "\n",
    "# Perform calculations for each variable\n",
    "for var, ds_var in variables.items():\n",
    "    results[var]['concat'] = combined_ds[ds_var]\n",
    "    results[var]['mean'] = combined_ds[ds_var].mean(dim='time', skipna=True)\n",
    "    results[var]['std'] = combined_ds[ds_var].std(dim='time', skipna=True)\n",
    "\n",
    "# Compute all results in parallel\n",
    "computed_results = compute(*[results[var]['mean'] for var in variables] + \n",
    "                           [results[var]['std'] for var in variables])\n",
    "\n",
    "# Organize results back into dictionaries\n",
    "for i, var in enumerate(variables):\n",
    "    results[var]['mean'] = computed_results[i]\n",
    "    results[var]['std'] = computed_results[i + len(variables)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1c1358",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the concatenated variables to a new .npz file\n",
    "np.savez(f'{expt_name}_{start_date.strftime(\"%Y%m%d\")}_{end_date.strftime(\"%Y%m%d\")}_tavg24_1d_lnd_Nt_concat.npz',\n",
    "         **{f'{var}_concat': results[var]['concat'].values for var in variables})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b1671e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the statistics to a new .npz file\n",
    "np.savez(f'{expt_name}_{start_date.strftime(\"%Y%m%d\")}_{end_date.strftime(\"%Y%m%d\")}_tavg24_1d_lnd_Nt_stats.npz',\n",
    "         **{f'mean_{var}': results[var]['mean'].values for var in variables},\n",
    "         **{f'std_{var}': results[var]['std'].values for var in variables})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98177614",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate the mean, etc. for each time step along the tile dimension\n",
    "ts_results = {var: {} for var in variables}\n",
    "for var in variables:\n",
    "    ts_results[var]['mean'] = combined_ds[variables[var]].mean(dim='tile', skipna=True)\n",
    "    ts_results[var]['std'] = combined_ds[variables[var]].std(dim='tile', skipna=True)\n",
    "\n",
    "# Compute all time series results in parallel\n",
    "ts_computed_results = compute(*[ts_results[var]['mean'] for var in variables] + \n",
    "                              [ts_results[var]['std'] for var in variables])\n",
    "\n",
    "# Organize time series results back into dictionaries\n",
    "for i, var in enumerate(variables):\n",
    "    ts_results[var]['mean'] = ts_computed_results[i]\n",
    "    ts_results[var]['std'] = ts_computed_results[i + len(variables)]\n",
    "\n",
    "# Save the time series to a new .npz file\n",
    "np.savez(f'{expt_name}_{start_date.strftime(\"%Y%m%d\")}_{end_date.strftime(\"%Y%m%d\")}_tavg24_1d_lnd_Nt_timeseries.npz',\n",
    "         **{f'ts_mean_{var}': ts_results[var]['mean'].values for var in variables},\n",
    "         **{f'ts_std_{var}': ts_results[var]['std'].values for var in variables})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-diag]",
   "language": "python",
   "name": "conda-env-.conda-diag-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
