{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_name = 'LS_OLv8_M36'\n",
    "expt_name_da = 'LS_DAv8_M36'\n",
    "\n",
    "start_date = datetime(2020, 1, 2)\n",
    "end_date = datetime(2020, 1, 6)\n",
    "\n",
    "start_date_str = start_date.strftime('%Y%m%d')\n",
    "end_date_str = end_date.strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_obsfcstana_extend_datetime(path, file_name, printflag=False):\n",
    "    # Define precisions\n",
    "    int_precision = 'int32'\n",
    "    float_precision = 'float32'\n",
    "    logical_precision = 'int32'\n",
    "\n",
    "    # Initialize lists for outputs\n",
    "    date_time_list = []\n",
    "    obs_assim_list = []\n",
    "    obs_species_list = []\n",
    "    obs_tilenum_list = []\n",
    "    obs_lon_list = []\n",
    "    obs_lat_list = []\n",
    "    obs_obs_list = []\n",
    "    obs_obsvar_list = []\n",
    "    obs_fcst_list = []\n",
    "    obs_fcstvar_list = []\n",
    "    obs_ana_list = []\n",
    "    obs_anavar_list = []\n",
    "\n",
    "    machfmt = 'b'\n",
    "    file_ext = '.bin'\n",
    "    # Build full file paths (note: file already includes the path)\n",
    "    files = [os.path.join(root, file) \n",
    "             for root, dirs, files in os.walk(path) \n",
    "             for file in files if file.startswith(file_name) and file.endswith(file_ext)]\n",
    "\n",
    "    if printflag:\n",
    "        print(files)\n",
    "\n",
    "    mode = 'rb' if machfmt == 'b' else 'rl'\n",
    "\n",
    "    for file in files:\n",
    "        with open(file, mode) as ifp:  # file already includes the path\n",
    "            if printflag:\n",
    "                print('Reading file', file, '...')\n",
    "            \n",
    "            # Read header and time stamp data\n",
    "            _ = np.fromfile(ifp, int_precision, 1)  # fortran_tag\n",
    "            N_obs = int(np.fromfile(ifp, int_precision, 1)[0])\n",
    "            # Read time components\n",
    "            year    = np.fromfile(ifp, int_precision, 1)\n",
    "            month   = np.fromfile(ifp, int_precision, 1)\n",
    "            day     = np.fromfile(ifp, int_precision, 1)\n",
    "            hour    = np.fromfile(ifp, int_precision, 1)\n",
    "            minute  = np.fromfile(ifp, int_precision, 1)\n",
    "            second  = np.fromfile(ifp, int_precision, 1)\n",
    "            dofyr   = np.fromfile(ifp, int_precision, 1)\n",
    "            pentad  = np.fromfile(ifp, int_precision, 1)\n",
    "            _ = np.fromfile(ifp, int_precision, 1)  # fortran_tag\n",
    "\n",
    "            # Ensure all variables are scalars\n",
    "            year = int(year.item()) if isinstance(year, (np.integer, np.ndarray)) else year\n",
    "            month = int(month.item()) if isinstance(month, (np.integer, np.ndarray)) else month\n",
    "            day = int(day.item()) if isinstance(day, (np.integer, np.ndarray)) else day\n",
    "            hour = int(hour.item()) if isinstance(hour, (np.integer, np.ndarray)) else hour\n",
    "            minute = int(minute.item()) if isinstance(minute, (np.integer, np.ndarray)) else minute\n",
    "            second = int(second.item()) if isinstance(second, (np.integer, np.ndarray)) else second\n",
    "            # Create a single datetime object for the timestamp info\n",
    "            date_time_tmp = datetime(year, month, day, hour, minute, int(second))\n",
    "            date_time_list.extend([date_time_tmp] * N_obs) \n",
    "\n",
    "            # Read observation assimilation flag\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            tmp_data = np.fromfile(ifp, logical_precision, N_obs)\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            # Vectorized conversion: nonzero becomes 1, else 0.\n",
    "            tmp_data2 = (tmp_data != 0).astype(np.int32).reshape(-1, 1)\n",
    "            obs_assim_list.append(tmp_data2)\n",
    "\n",
    "            # Read species information\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            obs_species_list.append(np.fromfile(ifp, int_precision, N_obs))\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            \n",
    "            # Read tile number information\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            obs_tilenum_list.append(np.fromfile(ifp, int_precision, N_obs))\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "\n",
    "            # Read longitude\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            obs_lon_list.append(np.fromfile(ifp, float_precision, N_obs))\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "\n",
    "            # Read latitude\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            obs_lat_list.append(np.fromfile(ifp, float_precision, N_obs))\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            \n",
    "            # Read observation value\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            obs_obs_list.append(np.fromfile(ifp, float_precision, N_obs))\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "\n",
    "            # Read observation variance\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            obs_obsvar_list.append(np.fromfile(ifp, float_precision, N_obs))\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "\n",
    "            # Read forecast value\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            obs_fcst_list.append(np.fromfile(ifp, float_precision, N_obs))\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "\n",
    "            # Read forecast variance\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            obs_fcstvar_list.append(np.fromfile(ifp, float_precision, N_obs))\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "\n",
    "            # Read analysis value\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            obs_ana_list.append(np.fromfile(ifp, float_precision, N_obs))\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "\n",
    "            # Read analysis variance\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            obs_anavar_list.append(np.fromfile(ifp, float_precision, N_obs))\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "\n",
    "    # After processing all files, concatenate lists into numpy arrays\n",
    "    obs_assim = np.concatenate(obs_assim_list) if obs_assim_list else np.array([])\n",
    "    obs_species = np.concatenate(obs_species_list) if obs_species_list else np.array([])\n",
    "    obs_tilenum = np.concatenate(obs_tilenum_list) if obs_tilenum_list else np.array([])\n",
    "    obs_lon = np.concatenate(obs_lon_list) if obs_lon_list else np.array([])\n",
    "    obs_lat = np.concatenate(obs_lat_list) if obs_lat_list else np.array([])\n",
    "    obs_obs = np.concatenate(obs_obs_list) if obs_obs_list else np.array([])\n",
    "    obs_obsvar = np.concatenate(obs_obsvar_list) if obs_obsvar_list else np.array([])\n",
    "    obs_fcst = np.concatenate(obs_fcst_list) if obs_fcst_list else np.array([])\n",
    "    obs_fcstvar = np.concatenate(obs_fcstvar_list) if obs_fcstvar_list else np.array([])\n",
    "    obs_ana = np.concatenate(obs_ana_list) if obs_ana_list else np.array([])\n",
    "    obs_anavar = np.concatenate(obs_anavar_list) if obs_anavar_list else np.array([])\n",
    "\n",
    "    return (date_time_list, obs_assim, obs_species, obs_tilenum, obs_lon, obs_lat, \n",
    "            obs_obs, obs_obsvar, obs_fcst, obs_fcstvar, obs_ana, obs_anavar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of obs: 9662196\n",
      "First few date_time values: [datetime.datetime(2020, 1, 5, 6, 0) datetime.datetime(2020, 1, 5, 6, 0)\n",
      " datetime.datetime(2020, 1, 5, 6, 0) datetime.datetime(2020, 1, 5, 6, 0)\n",
      " datetime.datetime(2020, 1, 5, 6, 0)]\n",
      "First few date_time_int values: [1578204000 1578204000 1578204000 1578204000 1578204000]\n",
      "Length of obs_da: 9278711\n",
      "obs dtype: float32, obs_da dtype: float32\n",
      "Length of obs after masking: 9260697\n",
      "Length of obs_da after masking: 9260697\n",
      "Number of unique tilenum values: 104973\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from helper.read_GEOSldas import read_ObsFcstAna, read_tilecoord, read_obs_param\n",
    "\n",
    "def compute_monthly_stats_OL(expdir, expid, domain, this_month, tc, obs_param, var_list, sub_expdir, sub_expid):\n",
    "\n",
    "    n_tile = tc['N_tile']\n",
    "    n_spec = len(obs_param)\n",
    "\n",
    "    start_time = this_month.replace(day=1,hour=3) \n",
    "    end_time = start_time + relativedelta(months=1)\n",
    "\n",
    "    data_sum = {}\n",
    "    data2_sum = {}\n",
    "\n",
    "    N_data = np.zeros((n_tile, n_spec))\n",
    "    oxf_sum = np.zeros((n_tile, n_spec))\n",
    "    oxa_sum = np.zeros((n_tile, n_spec))\n",
    "    fxa_sum = np.zeros((n_tile, n_spec))\n",
    "\n",
    "    for var in var_list:\n",
    "        data_sum[var] = np.zeros((n_tile, n_spec))\n",
    "        data2_sum[var] = np.zeros((n_tile, n_spec))\n",
    "\n",
    "    date_time = start_time\n",
    "    while date_time < end_time:\n",
    "\n",
    "        fname = expdir + expid + '/output/' + domain + '/ana/ens_avg/Y' + \\\n",
    "                date_time.strftime('%Y') + '/M' + \\\n",
    "                date_time.strftime('%m') + '/' + \\\n",
    "                expid + '.ens_avg.ldas_ObsFcstAna.' + \\\n",
    "                date_time.strftime('%Y%m%d_%H%M') + 'z.bin'\n",
    "\n",
    "        sub_fname = sub_expdir + sub_expid + '/output/' + domain + '/ana/ens_avg/Y' + \\\n",
    "                    date_time.strftime('%Y') + '/M' + \\\n",
    "                    date_time.strftime('%m') + '/' + \\\n",
    "                    sub_expid + '.ens_avg.ldas_ObsFcstAna.' + \\\n",
    "                    date_time.strftime('%Y%m%d_%H%M') + 'z.bin'\n",
    "\n",
    "        print(\"fname: \", fname)\n",
    "\n",
    "        OFA = read_ObsFcstAna(fname)\n",
    "\n",
    "        # Check uniqueness of (tilenum, species) in OFA\n",
    "        combined_keys = OFA['obs_tilenum'] * 100 + OFA['obs_species'].astype(int)\n",
    "        n_total = len(combined_keys)\n",
    "        n_unique = len(np.unique(combined_keys))\n",
    "        if n_total != n_unique:\n",
    "            print(f\"[WARNING] {n_total - n_unique} duplicate (tilenum, species) combinations found in {fname}\")\n",
    "        OFA_sub = read_ObsFcstAna(sub_fname)\n",
    "\n",
    "        # Check uniqueness of (tilenum, species) in OFA_sub\n",
    "        combined_keys_sub = OFA_sub['obs_tilenum'] * 100 + OFA_sub['obs_species'].astype(int)\n",
    "        n_total_sub = len(combined_keys_sub)\n",
    "        n_unique_sub = len(np.unique(combined_keys_sub))\n",
    "        if n_total_sub != n_unique_sub:\n",
    "            print(f\"[WARNING] {n_total_sub - n_unique_sub} duplicate (tilenum, species) combinations found in {sub_fname}\")\n",
    "\n",
    "        if len(OFA['obs_tilenum']) > 0 and len(OFA_sub['obs_tilenum']) > 0:\n",
    "\n",
    "            # Build unique identifiers for matching using tilenum and species\n",
    "            tilenum = OFA['obs_tilenum']\n",
    "            species = OFA['obs_species'].astype(int)\n",
    "            unique_id = tilenum * 100 + species\n",
    "\n",
    "            tilenum_sub = OFA_sub['obs_tilenum']\n",
    "            species_sub = OFA_sub['obs_species'].astype(int)\n",
    "            unique_id_sub = tilenum_sub * 100 + species_sub\n",
    "\n",
    "            # Find matching indices\n",
    "            common_ids, idx_main, idx_sub = np.intersect1d(unique_id, unique_id_sub, return_indices=True)\n",
    "            if len(common_ids) == 0:\n",
    "                date_time += timedelta(seconds=10800)\n",
    "                continue\n",
    "\n",
    "            # Subset main data\n",
    "            for var in var_list:\n",
    "                OFA[var] = OFA[var][idx_main]\n",
    "            OFA['obs_species'] = species[idx_main]\n",
    "            OFA['obs_lat'] = OFA['obs_lat'][idx_main]\n",
    "            OFA['obs_lon'] = OFA['obs_lon'][idx_main]\n",
    "            OFA['obs_tilenum'] = tilenum[idx_main]\n",
    "            if 'obs_assim' in OFA:\n",
    "                OFA['obs_assim'] = OFA['obs_assim'][idx_main]\n",
    "\n",
    "            # Replace obs_obs with subset values\n",
    "            OFA['obs_obs'] = OFA_sub['obs_obs'][idx_sub]\n",
    "\n",
    "            # Initialize full size variable to keep values\n",
    "            data_tile = {var: np.full((n_tile, n_spec), np.nan) for var in var_list}\n",
    "\n",
    "            for ispec in np.arange(n_spec):\n",
    "                this_species = int(obs_param[ispec]['species'])\n",
    "                masked_data = {}\n",
    "                if obs_param[ispec]['assim'] == 'T':\n",
    "                    mask = np.logical_and(OFA['obs_species'] == this_species, OFA['obs_assim'] == 1)\n",
    "                else:\n",
    "                    mask = OFA['obs_species'] == this_species\n",
    "\n",
    "                lat = OFA['obs_lat'][mask]\n",
    "                lon = OFA['obs_lon'][mask]\n",
    "                tilenum = OFA['obs_tilenum'][mask]\n",
    "\n",
    "                for var in var_list:\n",
    "                    masked_data[var] = OFA[var][mask]\n",
    "\n",
    "                tile_idx = np.where(np.isin(tc['tile_id'], tilenum))[0]\n",
    "\n",
    "                for var in var_list:\n",
    "                    data_tile[var][tile_idx, ispec] = masked_data[var]\n",
    "\n",
    "            is_valid = ~np.isnan(data_tile['obs_obs'])\n",
    "            N_data[is_valid] += 1\n",
    "            oxf_sum[is_valid] += data_tile['obs_obs'][is_valid] * data_tile['obs_fcst'][is_valid]\n",
    "            oxa_sum[is_valid] += data_tile['obs_obs'][is_valid] * data_tile['obs_ana'][is_valid]\n",
    "            fxa_sum[is_valid] += data_tile['obs_fcst'][is_valid] * data_tile['obs_ana'][is_valid]\n",
    "            for var in var_list:\n",
    "                data_sum[var][is_valid] += data_tile[var][is_valid]\n",
    "                data2_sum[var][is_valid] += data_tile[var][is_valid] ** 2\n",
    "\n",
    "        date_time = date_time + timedelta(seconds=10800)\n",
    "\n",
    "    return N_data, data_sum, data2_sum, oxf_sum, oxa_sum, fxa_sum\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    date_time = datetime(2015,5,1)\n",
    "    expdir = '/gpfsm/dnb05/projects/p51/SMAP_Nature/'\n",
    "    expid = 'SPL4SM_Vv8010_OPENLOOP'\n",
    "    sub_expdir = '/gpfsm/dnb05/projects/p51/SMAP_Nature/'\n",
    "    sub_expid = 'SPL4SM_Vv8010_DA_RUN'\n",
    "    domain = 'SMAP_EASEv2_M09_GLOBAL'\n",
    "    var_list = ['obs_obs', 'obs_obsvar', 'obs_fcst', 'obs_fcstvar', 'obs_ana', 'obs_anavar']\n",
    "    ftc = expdir+expid+'/output/'+domain+'/rc_out/'+expid+'.ldas_tilecoord.bin'\n",
    "    tc = read_tilecoord(ftc)\n",
    "\n",
    "    fop = expdir+expid+'/output/'+domain+'/rc_out/Y2015/M04/'+expid+'.ldas_obsparam.20150401_0000z.txt'\n",
    "    obs_param = read_obs_param(fop)\n",
    "\n",
    "    N_data, data_sum, data2_sum, oxf_sum, oxa_sum, fxa_sum = \\\n",
    "           compute_monthly_stats_OL(expdir, expid, domain, date_time, tc, obs_param, var_list, sub_expdir, sub_expid)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
