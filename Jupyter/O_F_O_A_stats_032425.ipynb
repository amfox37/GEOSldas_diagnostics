{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dateutil.relativedelta import relativedelta\n",
    "#from my_functions import read_obsfcstana_extend_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_name = 'LS_DAv8_M36'\n",
    "\n",
    "start_date = datetime(2000, 6, 1)\n",
    "end_date = datetime(2024, 4, 1)\n",
    "\n",
    "start_date_str = start_date.strftime('%Y%m%d')\n",
    "end_date_str = end_date.strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize arrays\n",
    "max_tilenum = 112573\n",
    "max_speciesnum = 13\n",
    "\n",
    "obs_cnt  = np.zeros((max_tilenum + 1, max_speciesnum + 1))\n",
    "obs_sum  = np.zeros((max_tilenum + 1, max_speciesnum + 1))\n",
    "obs2_sum = np.zeros((max_tilenum + 1, max_speciesnum + 1))\n",
    "fcst_sum  = np.zeros((max_tilenum + 1, max_speciesnum + 1))\n",
    "fcst2_sum = np.zeros((max_tilenum + 1, max_speciesnum + 1))\n",
    "ana_sum  = np.zeros((max_tilenum + 1, max_speciesnum + 1))\n",
    "ana2_sum = np.zeros((max_tilenum + 1, max_speciesnum + 1))\n",
    "omf_sum  = np.zeros((max_tilenum + 1, max_speciesnum + 1))\n",
    "omf2_sum = np.zeros((max_tilenum + 1, max_speciesnum + 1))\n",
    "oma_sum  = np.zeros((max_tilenum + 1, max_speciesnum + 1))\n",
    "oma2_sum = np.zeros((max_tilenum + 1, max_speciesnum + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_obsfcstana_extend_datetime(path, file_name, printflag=False):\n",
    "    # Define precisions\n",
    "    int_precision = 'int32'\n",
    "    float_precision = 'float32'\n",
    "    logical_precision = 'int32'\n",
    "\n",
    "    # Initialize lists for outputs\n",
    "    date_time_list = []\n",
    "    obs_assim_list = []\n",
    "    obs_species_list = []\n",
    "    obs_tilenum_list = []\n",
    "    obs_lon_list = []\n",
    "    obs_lat_list = []\n",
    "    obs_obs_list = []\n",
    "    obs_obsvar_list = []\n",
    "    obs_fcst_list = []\n",
    "    obs_fcstvar_list = []\n",
    "    obs_ana_list = []\n",
    "    obs_anavar_list = []\n",
    "\n",
    "    machfmt = 'b'\n",
    "    file_ext = '.bin'\n",
    "    # Build full file paths (note: file already includes the path)\n",
    "    files = [os.path.join(root, file) \n",
    "             for root, dirs, files in os.walk(path) \n",
    "             for file in files if file.startswith(file_name) and file.endswith(file_ext)]\n",
    "\n",
    "    if printflag:\n",
    "        print(files)\n",
    "\n",
    "    mode = 'rb' if machfmt == 'b' else 'rl'\n",
    "\n",
    "    for file in files:\n",
    "        with open(file, mode) as ifp:  # file already includes the path\n",
    "            if printflag:\n",
    "                print('Reading file', file, '...')\n",
    "            \n",
    "            # Read header and time stamp data\n",
    "            _ = np.fromfile(ifp, int_precision, 1)  # fortran_tag\n",
    "            N_obs = int(np.fromfile(ifp, int_precision, 1))\n",
    "            # Read time components\n",
    "            year    = np.fromfile(ifp, int_precision, 1)\n",
    "            month   = np.fromfile(ifp, int_precision, 1)\n",
    "            day     = np.fromfile(ifp, int_precision, 1)\n",
    "            hour    = np.fromfile(ifp, int_precision, 1)\n",
    "            minute  = np.fromfile(ifp, int_precision, 1)\n",
    "            second  = np.fromfile(ifp, int_precision, 1)\n",
    "            dofyr   = np.fromfile(ifp, int_precision, 1)\n",
    "            pentad  = np.fromfile(ifp, int_precision, 1)\n",
    "            _ = np.fromfile(ifp, int_precision, 1)  # fortran_tag\n",
    "\n",
    "            # Create a single dictionary for the timestamp info and extend the list\n",
    "            date_time_tmp = {\n",
    "                'year': year,\n",
    "                'month': month,\n",
    "                'day': day,\n",
    "                'hour': hour,\n",
    "                'min': minute,\n",
    "                'sec': second,\n",
    "                'dofyr': dofyr,\n",
    "                'pentad': pentad\n",
    "            }\n",
    "            date_time_list.extend([date_time_tmp] * N_obs) \n",
    "\n",
    "            # Read observation assimilation flag\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            tmp_data = np.fromfile(ifp, logical_precision, N_obs)\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            # Vectorized conversion: nonzero becomes 1, else 0.\n",
    "            tmp_data2 = (tmp_data != 0).astype(np.int32).reshape(-1, 1)\n",
    "            obs_assim_list.append(tmp_data2)\n",
    "\n",
    "            # Read species information\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            obs_species_list.append(np.fromfile(ifp, int_precision, N_obs))\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            \n",
    "            # Read tile number information\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            obs_tilenum_list.append(np.fromfile(ifp, int_precision, N_obs))\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "\n",
    "            # Read longitude\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            obs_lon_list.append(np.fromfile(ifp, float_precision, N_obs))\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "\n",
    "            # Read latitude\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            obs_lat_list.append(np.fromfile(ifp, float_precision, N_obs))\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            \n",
    "            # Read observation value\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            obs_obs_list.append(np.fromfile(ifp, float_precision, N_obs))\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "\n",
    "            # Read observation variance\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            obs_obsvar_list.append(np.fromfile(ifp, float_precision, N_obs))\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "\n",
    "            # Read forecast value\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            obs_fcst_list.append(np.fromfile(ifp, float_precision, N_obs))\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "\n",
    "            # Read forecast variance\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            obs_fcstvar_list.append(np.fromfile(ifp, float_precision, N_obs))\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "\n",
    "            # Read analysis value\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            obs_ana_list.append(np.fromfile(ifp, float_precision, N_obs))\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "\n",
    "            # Read analysis variance\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            obs_anavar_list.append(np.fromfile(ifp, float_precision, N_obs))\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "\n",
    "    # After processing all files, concatenate lists into numpy arrays\n",
    "    obs_assim = np.concatenate(obs_assim_list) if obs_assim_list else np.array([])\n",
    "    obs_species = np.concatenate(obs_species_list) if obs_species_list else np.array([])\n",
    "    obs_tilenum = np.concatenate(obs_tilenum_list) if obs_tilenum_list else np.array([])\n",
    "    obs_lon = np.concatenate(obs_lon_list) if obs_lon_list else np.array([])\n",
    "    obs_lat = np.concatenate(obs_lat_list) if obs_lat_list else np.array([])\n",
    "    obs_obs = np.concatenate(obs_obs_list) if obs_obs_list else np.array([])\n",
    "    obs_obsvar = np.concatenate(obs_obsvar_list) if obs_obsvar_list else np.array([])\n",
    "    obs_fcst = np.concatenate(obs_fcst_list) if obs_fcst_list else np.array([])\n",
    "    obs_fcstvar = np.concatenate(obs_fcstvar_list) if obs_fcstvar_list else np.array([])\n",
    "    obs_ana = np.concatenate(obs_ana_list) if obs_ana_list else np.array([])\n",
    "    obs_anavar = np.concatenate(obs_anavar_list) if obs_anavar_list else np.array([])\n",
    "\n",
    "    return (date_time_list, obs_species, obs_tilenum, obs_lon, obs_lat, \n",
    "            obs_obs, obs_obsvar, obs_fcst, obs_fcstvar, obs_ana, obs_anavar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently processing:  200006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfsm/dnb34/tdirs/batch/slurm.44563815.amfox/ipykernel_30718/1198794527.py:40: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  N_obs = int(np.fromfile(ifp, int_precision, 1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently processing:  200007\n",
      "Currently processing:  200008\n",
      "Currently processing:  200009\n",
      "Currently processing:  200010\n",
      "Currently processing:  200011\n",
      "Currently processing:  200012\n",
      "Currently processing:  200101\n",
      "Currently processing:  200102\n",
      "Currently processing:  200103\n",
      "Currently processing:  200104\n",
      "Currently processing:  200105\n",
      "Currently processing:  200106\n",
      "Currently processing:  200107\n",
      "Currently processing:  200108\n",
      "Currently processing:  200109\n",
      "Currently processing:  200110\n",
      "Currently processing:  200111\n",
      "Currently processing:  200112\n",
      "Currently processing:  200201\n",
      "Currently processing:  200202\n",
      "Currently processing:  200203\n",
      "Currently processing:  200204\n",
      "Currently processing:  200205\n",
      "Currently processing:  200206\n",
      "Currently processing:  200207\n",
      "Currently processing:  200208\n",
      "Currently processing:  200209\n",
      "Currently processing:  200210\n",
      "Currently processing:  200211\n",
      "Currently processing:  200301\n",
      "Currently processing:  200302\n",
      "Currently processing:  200303\n",
      "Currently processing:  200304\n",
      "Currently processing:  200305\n",
      "Currently processing:  200306\n",
      "Currently processing:  200307\n",
      "Currently processing:  200308\n",
      "Currently processing:  200309\n",
      "Currently processing:  200310\n",
      "Currently processing:  200311\n",
      "Currently processing:  200312\n",
      "Currently processing:  200401\n",
      "Currently processing:  200402\n",
      "Currently processing:  200403\n",
      "Currently processing:  200404\n",
      "Currently processing:  200405\n",
      "Currently processing:  200406\n",
      "Currently processing:  200407\n",
      "Currently processing:  200408\n",
      "Currently processing:  200409\n",
      "Currently processing:  200410\n",
      "Currently processing:  200411\n",
      "Currently processing:  200412\n",
      "Currently processing:  200501\n",
      "Currently processing:  200502\n",
      "Currently processing:  200503\n",
      "Currently processing:  200504\n",
      "Currently processing:  200505\n",
      "Currently processing:  200506\n",
      "Currently processing:  200508\n",
      "Currently processing:  200509\n",
      "Currently processing:  200510\n",
      "Currently processing:  200511\n",
      "Currently processing:  200512\n",
      "Currently processing:  200601\n",
      "Currently processing:  200602\n",
      "Currently processing:  200603\n",
      "Currently processing:  200604\n",
      "Currently processing:  200605\n",
      "Currently processing:  200606\n",
      "Currently processing:  200607\n",
      "Currently processing:  200608\n",
      "Currently processing:  200609\n",
      "Currently processing:  200610\n",
      "Currently processing:  200611\n",
      "Currently processing:  200612\n",
      "Currently processing:  200701\n",
      "Currently processing:  200702\n",
      "Currently processing:  200703\n",
      "Currently processing:  200704\n",
      "Currently processing:  200705\n",
      "Currently processing:  200706\n",
      "Currently processing:  200707\n",
      "Currently processing:  200708\n",
      "Currently processing:  200709\n",
      "Currently processing:  200710\n",
      "Currently processing:  200711\n",
      "Currently processing:  200712\n",
      "Currently processing:  200801\n",
      "Currently processing:  200802\n",
      "Currently processing:  200804\n",
      "Currently processing:  200805\n",
      "Currently processing:  200806\n",
      "Currently processing:  200807\n",
      "Currently processing:  200808\n",
      "Currently processing:  200809\n",
      "Currently processing:  200810\n",
      "Currently processing:  200811\n",
      "Currently processing:  200812\n",
      "Currently processing:  200901\n",
      "Currently processing:  200902\n",
      "Currently processing:  200903\n",
      "Currently processing:  200904\n",
      "Currently processing:  200905\n",
      "Currently processing:  200906\n",
      "Currently processing:  200907\n",
      "Currently processing:  200908\n",
      "Currently processing:  200909\n",
      "Currently processing:  200910\n",
      "Currently processing:  200911\n",
      "Currently processing:  200912\n",
      "Currently processing:  201001\n",
      "Currently processing:  201002\n",
      "Currently processing:  201003\n",
      "Currently processing:  201004\n",
      "Currently processing:  201005\n",
      "Currently processing:  201006\n",
      "Currently processing:  201007\n",
      "Currently processing:  201008\n",
      "Currently processing:  201009\n",
      "Currently processing:  201011\n",
      "Currently processing:  201012\n",
      "Currently processing:  201101\n",
      "Currently processing:  201102\n",
      "Currently processing:  201103\n",
      "Currently processing:  201104\n",
      "Currently processing:  201105\n",
      "Currently processing:  201106\n",
      "Currently processing:  201107\n",
      "Currently processing:  201108\n",
      "Currently processing:  201109\n",
      "Currently processing:  201110\n",
      "Currently processing:  201111\n",
      "Currently processing:  201112\n",
      "Currently processing:  201201\n",
      "Currently processing:  201202\n",
      "Currently processing:  201203\n",
      "Currently processing:  201204\n",
      "Currently processing:  201205\n",
      "Currently processing:  201206\n",
      "Currently processing:  201207\n",
      "Currently processing:  201208\n",
      "Currently processing:  201209\n",
      "Currently processing:  201210\n",
      "Currently processing:  201211\n",
      "Currently processing:  201212\n",
      "Currently processing:  201301\n",
      "Currently processing:  201302\n",
      "Currently processing:  201304\n",
      "Currently processing:  201305\n",
      "Currently processing:  201306\n",
      "Currently processing:  201307\n",
      "Currently processing:  201308\n",
      "Currently processing:  201309\n",
      "Currently processing:  201310\n",
      "Currently processing:  201311\n",
      "Currently processing:  201312\n",
      "Currently processing:  201401\n",
      "Currently processing:  201402\n",
      "Currently processing:  201403\n",
      "Currently processing:  201404\n",
      "Currently processing:  201405\n",
      "Currently processing:  201406\n",
      "Currently processing:  201407\n",
      "Currently processing:  201408\n",
      "Currently processing:  201409\n",
      "Currently processing:  201410\n",
      "Currently processing:  201411\n",
      "Currently processing:  201412\n",
      "Currently processing:  201501\n",
      "Currently processing:  201502\n",
      "Currently processing:  201503\n",
      "Currently processing:  201504\n",
      "Currently processing:  201505\n",
      "Currently processing:  201506\n",
      "Currently processing:  201507\n",
      "Currently processing:  201508\n",
      "Currently processing:  201509\n",
      "Currently processing:  201511\n",
      "Currently processing:  201512\n",
      "Currently processing:  201601\n",
      "Currently processing:  201602\n",
      "Currently processing:  201603\n",
      "Currently processing:  201604\n",
      "Currently processing:  201605\n",
      "Currently processing:  201606\n",
      "Currently processing:  201607\n",
      "Currently processing:  201608\n",
      "Currently processing:  201609\n",
      "Currently processing:  201610\n",
      "Currently processing:  201611\n",
      "Currently processing:  201612\n",
      "Currently processing:  201701\n",
      "Currently processing:  201702\n",
      "Currently processing:  201703\n",
      "Currently processing:  201704\n",
      "Currently processing:  201705\n",
      "Currently processing:  201706\n",
      "Currently processing:  201707\n",
      "Currently processing:  201708\n",
      "Currently processing:  201709\n",
      "Currently processing:  201710\n",
      "Currently processing:  201711\n",
      "Currently processing:  201712\n",
      "Currently processing:  201801\n",
      "Currently processing:  201802\n",
      "Currently processing:  201804\n",
      "Currently processing:  201805\n",
      "Currently processing:  201806\n",
      "Currently processing:  201807\n",
      "Currently processing:  201808\n",
      "Currently processing:  201809\n",
      "Currently processing:  201810\n",
      "Currently processing:  201811\n",
      "Currently processing:  201812\n",
      "Currently processing:  201901\n",
      "Currently processing:  201902\n",
      "Currently processing:  201903\n",
      "Currently processing:  201904\n",
      "Currently processing:  201905\n",
      "Currently processing:  201906\n",
      "Currently processing:  201907\n",
      "Currently processing:  201908\n",
      "Currently processing:  201909\n",
      "Currently processing:  201910\n",
      "Currently processing:  201911\n",
      "Currently processing:  201912\n",
      "Currently processing:  202001\n",
      "Currently processing:  202002\n",
      "Currently processing:  202003\n",
      "Currently processing:  202004\n",
      "Currently processing:  202005\n",
      "Currently processing:  202006\n",
      "Currently processing:  202007\n",
      "Currently processing:  202008\n",
      "Currently processing:  202009\n",
      "Currently processing:  202011\n",
      "Currently processing:  202012\n",
      "Currently processing:  202101\n",
      "Currently processing:  202102\n",
      "Currently processing:  202103\n",
      "Currently processing:  202104\n",
      "Currently processing:  202105\n",
      "Currently processing:  202106\n",
      "Currently processing:  202107\n",
      "Currently processing:  202108\n",
      "Currently processing:  202109\n",
      "Currently processing:  202110\n",
      "Currently processing:  202111\n",
      "Currently processing:  202112\n",
      "Currently processing:  202201\n",
      "Currently processing:  202202\n",
      "Currently processing:  202203\n",
      "Currently processing:  202204\n",
      "Currently processing:  202205\n",
      "Currently processing:  202206\n",
      "Currently processing:  202207\n",
      "Currently processing:  202208\n",
      "Currently processing:  202209\n",
      "Currently processing:  202210\n",
      "Currently processing:  202211\n",
      "Currently processing:  202212\n",
      "Currently processing:  202301\n",
      "Currently processing:  202302\n",
      "Currently processing:  202304\n",
      "Currently processing:  202305\n",
      "Currently processing:  202306\n",
      "Currently processing:  202307\n",
      "Currently processing:  202308\n",
      "Currently processing:  202309\n",
      "Currently processing:  202310\n",
      "Currently processing:  202311\n",
      "Currently processing:  202312\n",
      "Currently processing:  202401\n",
      "Currently processing:  202402\n",
      "Currently processing:  202403\n",
      "CPU times: user 3h 5min 27s, sys: 1min 23s, total: 3h 6min 51s\n",
      "Wall time: 4h 2min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Calculate the daily statistics in observation space\n",
    "\n",
    "# Define the path directory\n",
    "# path = f'/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/land_sweeper/{expt_name}/output/SMAP_EASEv2_M36_GLOBAL/ana/ens_avg'\n",
    "path = f'/discover/nobackup/projects/land_da/Experiment_archive/M21C_land_sweeper_DAv8_M36/{expt_name}/output/SMAP_EASEv2_M36_GLOBAL/ana/ens_avg'\n",
    "\n",
    "# Define the common file name start\n",
    "file_name_start = f'{expt_name}.ens_avg.ldas_ObsFcstAna.'\n",
    "\n",
    "# Define the print flag\n",
    "printflag = False\n",
    "\n",
    "# Loop over the dates\n",
    "current_date = start_date\n",
    "\n",
    "while current_date <= end_date:\n",
    "    # Define the file name for the current date\n",
    "    file_name = file_name_start + current_date.strftime('%Y%m')\n",
    "    print('Currently processing: ',current_date.strftime('%Y%m'))\n",
    "    \n",
    "    # Call the read_obsfcstana function for the current file\n",
    "    date_time, species, tilenum, lon, lat, obs, obsvar, fcst, fcstvar, ana, anavar = read_obsfcstana_extend_datetime(path, file_name, printflag)\n",
    "\n",
    "    # Increment the current date by one day\n",
    "    current_date += timedelta(days=1) \n",
    "\n",
    "    # Convert to list of datetime objects\n",
    "    datetime_list = [\n",
    "        datetime(\n",
    "            int(entry['year'][0]),\n",
    "            int(entry['month'][0]),\n",
    "            int(entry['day'][0]),\n",
    "            int(entry['hour'][0]),\n",
    "            int(entry['min'][0]),\n",
    "            int(entry['sec'][0])\n",
    "        )\n",
    "        for entry in date_time\n",
    "    ]\n",
    "\n",
    "    # Convert to numpy array of datetime objects\n",
    "    datetime_array = np.array(datetime_list)\n",
    "\n",
    "    # Calculate the difference between the observation and forecast and observation and analysis\n",
    "    omf = obs - fcst\n",
    "    oma = obs - ana \n",
    "\n",
    "    # Find unique species values and their number\n",
    "    unique_species, counts = np.unique(species, return_counts=True)\n",
    "    num_unique_species = len(unique_species)\n",
    "\n",
    "    # Find unique tilenum values\n",
    "    unique_tilenum = np.unique(tilenum)\n",
    "\n",
    "    # Find the number of unique tilenum values\n",
    "    num_unique_tilenum = len(unique_tilenum)\n",
    "\n",
    "    # Sort the arrays based on tilenum\n",
    "    sort_indices = np.argsort(tilenum)\n",
    "    sorted_tilenum = tilenum[sort_indices]\n",
    "    sorted_species = species[sort_indices]\n",
    "    sorted_obs = obs[sort_indices]\n",
    "    sorted_fcst = fcst[sort_indices]\n",
    "    sorted_ana = ana[sort_indices]\n",
    "    sorted_omf = omf[sort_indices]\n",
    "    sorted_oma = oma[sort_indices]\n",
    "    sorted_datetime_array = datetime_array[sort_indices]\n",
    "\n",
    "    # Find the unique tilenum values and their counts\n",
    "    unique_tilenum, counts = np.unique(sorted_tilenum, return_counts=True)\n",
    "\n",
    "    # Calculate the indices where the groups should be split\n",
    "    split_indices = np.cumsum(counts)[:-1]\n",
    "\n",
    "    # Split the sorted arrays based on the split indices\n",
    "    tilenum_tile = np.split(sorted_tilenum, split_indices)\n",
    "    species_tile = np.split(sorted_species, split_indices)\n",
    "    obs_tile = np.split(sorted_obs, split_indices)\n",
    "    fcst_tile = np.split(sorted_fcst, split_indices)\n",
    "    ana_tile = np.split(sorted_ana, split_indices)\n",
    "    omf_tile = np.split(sorted_omf, split_indices)\n",
    "    oma_tile = np.split(sorted_oma, split_indices)\n",
    "    datetime_tile = np.split(sorted_datetime_array, split_indices)\n",
    "\n",
    "    # Loop over the unique tiles\n",
    "\n",
    "    for i in range(num_unique_tilenum):\n",
    "        tc = int(tilenum_tile[i][0])  # Current tile number\n",
    "\n",
    "        # Create a dictionary to store indices for each species in the current tile\n",
    "        species_indices_dict = {sc: np.where(species_tile[i] == sc)[0] for sc in unique_species}\n",
    "\n",
    "        for sc in unique_species:\n",
    "            species_indices = species_indices_dict[sc]\n",
    "\n",
    "            if len(species_indices) > 0:\n",
    "                sc = int(sc)  # Current species number\n",
    "                obs_cnt[tc, sc] += len(species_indices)\n",
    "                obs_sum[tc, sc] += np.sum(obs_tile[i][species_indices])\n",
    "                obs2_sum[tc, sc] += np.sum(obs_tile[i][species_indices]**2)\n",
    "                fcst_sum[tc, sc] += np.sum(fcst_tile[i][species_indices])\n",
    "                fcst2_sum[tc, sc] += np.sum(fcst_tile[i][species_indices]**2)\n",
    "                ana_sum[tc, sc] += np.sum(ana_tile[i][species_indices])\n",
    "                ana2_sum[tc, sc] += np.sum(ana_tile[i][species_indices]**2)\n",
    "                omf_sum[tc, sc] += np.sum(omf_tile[i][species_indices])\n",
    "                omf2_sum[tc, sc] += np.sum(omf_tile[i][species_indices]**2)\n",
    "                oma_sum[tc, sc] += np.sum(oma_tile[i][species_indices])\n",
    "                oma2_sum[tc, sc] += np.sum(oma_tile[i][species_indices]**2)\n",
    "\n",
    "    current_date += relativedelta(months=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the sums and sums of squares to a file\n",
    "\n",
    "output_filename = f'{expt_name}_{start_date_str}_{end_date_str}_sum_sumofsquares.npz'\n",
    "\n",
    "np.savez(\n",
    "    output_filename,\n",
    "    obs_cnt=obs_cnt,\n",
    "    obs_sum=obs_sum,\n",
    "    obs2_sum=obs2_sum,\n",
    "    fcst_sum=fcst_sum,\n",
    "    fcst2_sum=fcst2_sum,\n",
    "    ana_sum=ana_sum,\n",
    "    ana2_sum=ana2_sum,\n",
    "    omf_sum=omf_sum,\n",
    "    omf2_sum=omf2_sum,\n",
    "    oma_sum=oma_sum,\n",
    "    oma2_sum=oma2_sum\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfsm/dnb34/tdirs/batch/slurm.44563815.amfox/ipykernel_30718/3550111383.py:37: RuntimeWarning: invalid value encountered in sqrt\n",
      "  obs_std[valid_mask] = np.sqrt(obs_var[valid_mask])\n",
      "/gpfsm/dnb34/tdirs/batch/slurm.44563815.amfox/ipykernel_30718/3550111383.py:38: RuntimeWarning: invalid value encountered in sqrt\n",
      "  fcst_std[valid_mask] = np.sqrt(fcst_var[valid_mask])\n",
      "/gpfsm/dnb34/tdirs/batch/slurm.44563815.amfox/ipykernel_30718/3550111383.py:39: RuntimeWarning: invalid value encountered in sqrt\n",
      "  ana_std[valid_mask] = np.sqrt(ana_var[valid_mask])\n",
      "/gpfsm/dnb34/tdirs/batch/slurm.44563815.amfox/ipykernel_30718/3550111383.py:40: RuntimeWarning: invalid value encountered in sqrt\n",
      "  omf_std[valid_mask] = np.sqrt(omf_var[valid_mask])\n",
      "/gpfsm/dnb34/tdirs/batch/slurm.44563815.amfox/ipykernel_30718/3550111383.py:41: RuntimeWarning: invalid value encountered in sqrt\n",
      "  oma_std[valid_mask] = np.sqrt(oma_var[valid_mask])\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean and standard deviation in observation space\n",
    "\n",
    "obs_mean = np.zeros_like(obs_cnt)\n",
    "obs_var = np.zeros_like(obs_cnt)\n",
    "obs_std = np.zeros_like(obs_cnt)\n",
    "fcst_mean = np.zeros_like(obs_cnt)\n",
    "fcst_var = np.zeros_like(obs_cnt)\n",
    "fcst_std = np.zeros_like(obs_cnt)\n",
    "ana_mean = np.zeros_like(obs_cnt)\n",
    "ana_var = np.zeros_like(obs_cnt)\n",
    "ana_std = np.zeros_like(obs_cnt)\n",
    "omf_mean = np.zeros_like(obs_cnt)\n",
    "omf_var = np.zeros_like(obs_cnt)\n",
    "omf_std = np.zeros_like(obs_cnt)\n",
    "oma_mean = np.zeros_like(obs_cnt)\n",
    "oma_var = np.zeros_like(obs_cnt)\n",
    "oma_std = np.zeros_like(obs_cnt)\n",
    "\n",
    "# Avoid division by zero\n",
    "valid_mask = obs_cnt > 1\n",
    "\n",
    "# Calculate the mean only for valid entries\n",
    "obs_mean[valid_mask] = obs_sum[valid_mask] / obs_cnt[valid_mask]\n",
    "fcst_mean[valid_mask] = fcst_sum[valid_mask] / obs_cnt[valid_mask]\n",
    "ana_mean[valid_mask] = ana_sum[valid_mask] / obs_cnt[valid_mask]\n",
    "omf_mean[valid_mask] = omf_sum[valid_mask] / obs_cnt[valid_mask]\n",
    "oma_mean[valid_mask] = oma_sum[valid_mask] / obs_cnt[valid_mask]\n",
    "\n",
    "# Calculate variance using the MATLAB approach for valid entries\n",
    "obs_var[valid_mask] = (obs2_sum[valid_mask] - obs_cnt[valid_mask] * obs_mean[valid_mask]**2) / (obs_cnt[valid_mask] - 1)\n",
    "fcst_var[valid_mask] = (fcst2_sum[valid_mask] - obs_cnt[valid_mask] * fcst_mean[valid_mask]**2) / (obs_cnt[valid_mask] - 1)\n",
    "ana_var[valid_mask] = (ana2_sum[valid_mask] - obs_cnt[valid_mask] * ana_mean[valid_mask]**2) / (obs_cnt[valid_mask] - 1)\n",
    "omf_var[valid_mask] = (omf2_sum[valid_mask] - obs_cnt[valid_mask] * omf_mean[valid_mask]**2) / (obs_cnt[valid_mask] - 1)\n",
    "oma_var[valid_mask] = (oma2_sum[valid_mask] - obs_cnt[valid_mask] * oma_mean[valid_mask]**2) / (obs_cnt[valid_mask] - 1)\n",
    "\n",
    "# Calculate the standard deviation\n",
    "obs_std[valid_mask] = np.sqrt(obs_var[valid_mask])\n",
    "fcst_std[valid_mask] = np.sqrt(fcst_var[valid_mask])\n",
    "ana_std[valid_mask] = np.sqrt(ana_var[valid_mask])\n",
    "omf_std[valid_mask] = np.sqrt(omf_var[valid_mask])\n",
    "oma_std[valid_mask] = np.sqrt(oma_var[valid_mask])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output saved to LS_DAv8_M36_20000601_20240401_obsfcstana_stats.npz\n"
     ]
    }
   ],
   "source": [
    "# Save all output into one file using experiment name, start and end date\n",
    "output_filename = f\"{expt_name}_{start_date_str}_{end_date_str}_obsfcstana_stats.npz\"\n",
    "\n",
    "np.savez(\n",
    "    output_filename,\n",
    "    obs_mean=obs_mean,\n",
    "    obs_std=obs_std,\n",
    "    fcst_mean=fcst_mean,\n",
    "    fcst_std=fcst_std,\n",
    "    ana_mean=ana_mean,\n",
    "    ana_std=ana_std,\n",
    "    omf_mean=omf_mean,\n",
    "    omf_std=omf_std,\n",
    "    oma_mean=oma_mean,\n",
    "    oma_std=oma_std\n",
    ")\n",
    "\n",
    "print(f\"Output saved to {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-diag]",
   "language": "python",
   "name": "conda-env-.conda-diag-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
